{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already satisfied: scrapy in /home/antoniar/virtenv/lib/python2.7/site-packages (1.7.3)\n",
      "Requirement already satisfied: parsel>=1.5 in /home/antoniar/virtenv/lib/python2.7/site-packages (from scrapy) (1.5.2)\n",
      "Requirement already satisfied: lxml; python_version != \"3.4\" in /home/antoniar/virtenv/lib/python2.7/site-packages (from scrapy) (4.4.0)\n",
      "Requirement already satisfied: pyOpenSSL in /home/antoniar/virtenv/lib/python2.7/site-packages (from scrapy) (19.0.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in /home/antoniar/virtenv/lib/python2.7/site-packages (from scrapy) (1.21.0)\n",
      "Requirement already satisfied: queuelib in /home/antoniar/virtenv/lib/python2.7/site-packages (from scrapy) (1.5.0)\n",
      "Requirement already satisfied: service-identity in /home/antoniar/virtenv/lib/python2.7/site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: Twisted>=13.1.0; python_version != \"3.4\" in /home/antoniar/virtenv/lib/python2.7/site-packages (from scrapy) (19.2.1)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in /home/antoniar/virtenv/lib/python2.7/site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/antoniar/virtenv/lib/python2.7/site-packages (from scrapy) (1.12.0)\n",
      "Requirement already satisfied: cssselect>=0.9 in /home/antoniar/virtenv/lib/python2.7/site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: functools32; python_version < \"3.0\" in /home/antoniar/virtenv/lib/python2.7/site-packages (from parsel>=1.5->scrapy) (3.2.3.post2)\n",
      "Requirement already satisfied: cryptography>=2.3 in /home/antoniar/virtenv/lib/python2.7/site-packages (from pyOpenSSL->scrapy) (2.7)\n",
      "Requirement already satisfied: attrs>=16.0.0 in /home/antoniar/virtenv/lib/python2.7/site-packages (from service-identity->scrapy) (19.1.0)\n",
      "Requirement already satisfied: ipaddress; python_version < \"3.3\" in /home/antoniar/virtenv/lib/python2.7/site-packages (from service-identity->scrapy) (1.0.22)\n",
      "Requirement already satisfied: pyasn1 in /home/antoniar/virtenv/lib/python2.7/site-packages (from service-identity->scrapy) (0.4.6)\n",
      "Requirement already satisfied: pyasn1-modules in /home/antoniar/virtenv/lib/python2.7/site-packages (from service-identity->scrapy) (0.2.6)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in /home/antoniar/virtenv/lib/python2.7/site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (19.0.0)\n",
      "Requirement already satisfied: zope.interface>=4.4.2 in /home/antoniar/virtenv/lib/python2.7/site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (4.6.0)\n",
      "Requirement already satisfied: PyHamcrest>=1.9.0 in /home/antoniar/virtenv/lib/python2.7/site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (1.9.0)\n",
      "Requirement already satisfied: constantly>=15.1 in /home/antoniar/virtenv/lib/python2.7/site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (15.1.0)\n",
      "Requirement already satisfied: incremental>=16.10.1 in /home/antoniar/virtenv/lib/python2.7/site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (17.5.0)\n",
      "Requirement already satisfied: Automat>=0.3.0 in /home/antoniar/virtenv/lib/python2.7/site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (0.7.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /home/antoniar/virtenv/lib/python2.7/site-packages (from cryptography>=2.3->pyOpenSSL->scrapy) (1.12.3)\n",
      "Requirement already satisfied: enum34; python_version < \"3\" in /home/antoniar/virtenv/lib/python2.7/site-packages (from cryptography>=2.3->pyOpenSSL->scrapy) (1.1.6)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /home/antoniar/virtenv/lib/python2.7/site-packages (from cryptography>=2.3->pyOpenSSL->scrapy) (0.24.0)\n",
      "Requirement already satisfied: idna>=2.5 in /home/antoniar/virtenv/lib/python2.7/site-packages (from hyperlink>=17.1.1->Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (2.8)\n",
      "Requirement already satisfied: setuptools in /home/antoniar/virtenv/lib/python2.7/site-packages (from zope.interface>=4.4.2->Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (41.0.1)\n",
      "Requirement already satisfied: pycparser in /home/antoniar/virtenv/lib/python2.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3->pyOpenSSL->scrapy) (2.19)\n",
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already satisfied: numpy in /home/antoniar/virtenv/lib/python2.7/site-packages (1.16.4)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import io, os, sys, types\n",
    "!{sys.executable} -m pip install scrapy \n",
    "# Imports own outside scripts\n",
    "import Databaseloader as dl\n",
    "import loadinvizerfit as lif\n",
    "import jsonwriter\n",
    "import readandplotfits as rpf\n",
    "import writereg as wr\n",
    "import dbtools\n",
    "import cutout as ct\n",
    "import jsondatabase as jsbase\n",
    "#########################################\n",
    "import json\n",
    "import glob\n",
    "import matplotlib\n",
    "import loadjson as ljs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tkp.db\n",
    "from astropy.coordinates import SkyCoord\n",
    "from tkp.db.model import Varmetric\n",
    "from tkp.db.model import Runningcatalog\n",
    "from tkp.db.model import Newsource\n",
    "from tkp.db.model import Extractedsource\n",
    "from tkp.db.model import Image\n",
    "import operator\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy.orm import relationship\n",
    "#import Tools\n",
    "#import generic_tools\n",
    "#import plotting_tools\n",
    "from scipy.stats import norm\n",
    "import pylab\n",
    "pylab.rcParams['legend.loc'] = 'best'\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.font_manager import FontProperties\n",
    "#from astroML import density_estimation\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.spatial import distance\n",
    "import scipy.stats as ss\n",
    "import scipy.optimize as op\n",
    "import scipy.integrate as si\n",
    "!{sys.executable} -m pip install numpy\n",
    "\n",
    "# !{sys.executable} -m pip install bokeh\n",
    "# from bokeh.plotting import figure, output_notebook, show\n",
    "# from bokeh.models import DatetimeTickFormatter\n",
    "# from bokeh.models import ColumnDataSource, Whisker\n",
    "# from bokeh.io import export_png\n",
    "# output_notebook()\n",
    "matplotlib.rcParams.update({'errorbar.capsize': 2})\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = 'postgresql'\n",
    "host = 'vlo.science.uva.nl'\n",
    "port = 5432 \n",
    "user = 'zmeyers'\n",
    "password = '5EmXFidPKclW'\n",
    "database='DDbatch2'\n",
    "\n",
    "\n",
    "websiteURL = 'http://banana.transientskp.org/r4/vlo_'+database+'/runningcatalog/'\n",
    "latexURL = '\\url{http://banana.transientskp.org/r4/vlo_'+database+'/runningcatalog/'\n",
    "latexHREF = '\\href{http://banana.transientskp.org/r4/vlo_'+database+'/runningcatalog/'\n",
    "query_loglevel = logging.WARNING  # Set to INFO to see queries, otherwise WARNING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is sqlalchemy script to login to the Banana database\n",
    "logging.getLogger('sqlalchemy.engine').setLevel(query_loglevel)\n",
    "db = tkp.db.Database(engine=engine, host=host, port=port,\n",
    "                     user=user, password=password, database=database)\n",
    "db.connect()\n",
    "session = db.Session()\n",
    "\n",
    "# Here i get the peak flux and the error on the peak flux from all the sources in the database\n",
    "fpeak = session.query(Extractedsource.f_peak).all()\n",
    "fpeake = session.query(Extractedsource.f_peak_err).all()\n",
    "typesextract = session.query(Extractedsource.fit_type).all()\n",
    "# arParams = session.query(Varmetric,Runningcatalog).select_from(join(Varmetric,Runningcatalog)).filter(Runningcatalog.dataset_id == dataset_id).all()\n",
    "califreq = np.load(\"freqlist.npy\")\n",
    "califlux = np.load(\"fluxlist.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left off here <a name='bookmark' />\n",
    "\n",
    "Go to <a href=#bookmark2>my bookmark</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query to find the variability parameters of the sources in a specific dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here I specifiy which dataset of the database to use\n",
    "dataset_id = 33\n",
    "timescale = \"P20_eight\"\n",
    "technique = database\n",
    "savefigs = True\n",
    "# runcat_id = 16077\n",
    "\n",
    "# VarParams = session.query(Varmetric,Runningcatalog).select_from(join(Varmetric,Runningcatalog)).filter(Runningcatalog.dataset_id == dataset_id).all()\n",
    "# imagecontrol = session.query(Runningcatalog,Image).filter(Runningcatalog.dataset_id == dataset_id).all()\n",
    "session = dbtools.access(engine,host,port,user,password,database)\n",
    "tables = ['image','varmetric','newsource']\n",
    "PandasParams = dbtools.GetPandaExtracted(session,dataset_id,tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print len(VarParams)\n",
    "# print len(imagecontrol)\n",
    "# for i in imagecontrol:\n",
    "#     print i\n",
    "print PandasParams.keys()\n",
    "newPandas = PandasParams.drop_duplicates(subset='xtrsrc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 2d array of all the sources except for the transients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotdata = [[VarParams[i].Runningcatalog.id, VarParams[i].Runningcatalog.wm_ra,\\\n",
    "#              VarParams[i].Runningcatalog.wm_decl,VarParams[i].Runningcatalog.avg_ra_err,\\\n",
    "#              VarParams[i].Runningcatalog.avg_decl_err, VarParams[i].Runningcatalog.datapoints,\\\n",
    "#              session.query(Newsource).filter(Newsource.id==VarParams[i].Varmetric.newsource).one().newsource_type,\\\n",
    "#              VarParams[i].Varmetric.newsource,VarParams[i].Varmetric.lightcurve_max,\n",
    "#              session.query(Newsource).filter(Newsource.id==VarParams[i].Varmetric.newsource).one().trigger_xtrsrc.id,VarParams[i].Varmetric.eta_int]\\\n",
    "#             for i in range(len(VarParams)) if VarParams[i].Varmetric.newsource != None]\n",
    "# for i in plotdata:\n",
    "#     if i[0] ==2877:\n",
    "#         print i\n",
    "# newPandas = PandasParams\n",
    "# print newPandas['lightcurve_median']\n",
    "# print PandasParams\n",
    "# print len(newPandas)\n",
    "# # for i in newPandas['url']:\n",
    "# #     print i\n",
    "# print PandasParams['fit_type']\n",
    "# print PandasParams['runcat']\n",
    "# print PandasParams['fit_type']\n",
    "# for i in range(len(PandasParams['runcat'])):\n",
    "# #     print PandasParams['runcat'][i]\n",
    "#     if PandasParams['runcat'][i] == 5774:\n",
    "#         print 'hoi'\n",
    "#         print PandasParams['fit_type'][i]\n",
    "# #         if PandasParams['fit_type'][i]==0:\n",
    "# #             print PandasParams['url'][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata = [[i.runcat, i.wm_ra,\\\n",
    "             i.wm_decl,i.avg_ra_err,\\\n",
    "             i.avg_decl_err, i.datapoints,\\\n",
    "             i.newsource_type,\\\n",
    "             i.newsource,i.lightcurve_max,\n",
    "             i.xtrsrc,i.eta_int,i.url]\\\n",
    "            for index,i in newPandas.iterrows() if i.newsource != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in plotdata:\n",
    "#     if i[7] ==5229:\n",
    "# #         print i[9]-1\n",
    "# #         print i\n",
    "        \n",
    "# #         print fpeak[i[9]-1][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The de Ruiter distance as shown in the Trap Paper section 4.4 https://arxiv.org/abs/1503.01526 \n",
    "\n",
    "def CalcDeRuiter(transient,ra2,ra2e,dec2,dec2e):\n",
    "\n",
    "    ra1 = transient['ra']\n",
    "    dec1 = transient['dec']\n",
    "    ra1e = transient['rae']\n",
    "    dec1e = transient['dece']\n",
    "\n",
    "\n",
    "    r=(np.sqrt((((-1*ra2 +ra1)**2)*(np.cos((dec1+dec2)/2))**2)/\\\n",
    "                       (ra1e**2+ra2e**2)+((-1*dec2+dec1)**2/(dec1e**2+dec2e**2))))\n",
    "    return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the fluxes heavily inspired on the de Ruiter distance as used by Bart's thesis: https://api-alumni.nl/media/uploads/theses/phd/lha-scheers-phd.pdf page 55\n",
    "\n",
    "def CompareFluxes(transient,pflux2,pflux2e,scale=1):\n",
    "    pflux1 = transient['pflux']*scale\n",
    "    pflux1e = transient['pfluxe']*scale\n",
    "    \n",
    "    r = np.sqrt((((-1*pflux2 +pflux1)**2))/\\\n",
    "                       (pflux1e**2+pflux2e**2))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the frequency flux scale based on supplied califreq and califlux data\n",
    "\n",
    "def CalcFreqScale(transient,datafreq,califreq,califlux):\n",
    "    \"\"\"Function for calculating the frequency scale\"\"\"\n",
    "    transfreq = transient.freq\n",
    "    for i in range(len(califreq)):\n",
    "        if transfreq - 0.005 <= califreq[i] <= transfreq + 0.005:\n",
    "            oldflux = califlux[i]\n",
    "        if datafreq - 0.005 <= califreq[i] <= datafreq + 0.005:\n",
    "            newflux = califlux[i]\n",
    "    scale = newflux/oldflux\n",
    "    return scale\n",
    "\n",
    "def CalcRelFlux(transient,datafreq,dataflux):\n",
    "    transfreq = transient.freq\n",
    "    scale = np.power((transfreq/datafreq),-0.7)*dataflux \n",
    "    return scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for pruning our candidate list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for comparing transient candidate against external databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CheckSimOutsideDatabase(data,sources,rcheck,ycheck,checklight,gamma,Cali,deruiter = True,euccutoff = 0.06):\n",
    "    \"\"\" Function for checking against outside database the data entry is for the database rcheck is condition \\\n",
    "where we check deruiter against, ycheck is where we check de flux against and checklight,gamma,deruiter\\\n",
    "are booleans which switch on checking the flux(checklight), checking using error on the flux(gamma) and \\\n",
    "using deruiter distance\n",
    "\n",
    "\"\"\"\n",
    "    masterindex = []\n",
    "    savedilist = []\n",
    "    print 'before:'\n",
    "    if Cali:\n",
    "        scale =  CalcFreqScale(sources[0],data.freq,califreq,califlux)\n",
    "    else:\n",
    "        scale = CalcRelFlux(sources[0],data.freq,data.pflux)\n",
    "\n",
    "    print len(sources)\n",
    "    \n",
    "    for i in sources:\n",
    "        indexlist = []\n",
    "\n",
    "        r = CalcDeRuiter(vars(i),np.array(data.ra),np.array(data.rae),np.array(data.dec),np.array(data.dece))\n",
    "        if gamma:\n",
    "            y = CompareFluxes(vars(i),np.array(data.pflux),np.array(data.pfluxe),scale)\n",
    "\n",
    "            for j in range(len(r)):\n",
    "\n",
    "                if r[j] <=rcheck:\n",
    "                    indexlist.append([j,r[j]])\n",
    "\n",
    "            if checklight and indexlist:\n",
    "                pfluxlist = []\n",
    "                pfluxelist = []\n",
    "\n",
    "                indexvalue = np.argmin(np.array(indexlist)[:,1])\n",
    "                pfluxlist.append(data.pflux[indexlist[indexvalue][0]])\n",
    "                pfluxelist.append(data.pfluxe[indexlist[indexvalue][0]])\n",
    "\n",
    "                y = CompareFluxes(vars(i),np.array(pfluxlist),np.array(pfluxelist))\n",
    "\n",
    "\n",
    "                if y[0]>=ycheck:\n",
    "\n",
    "                    FluxVar(vars(i),indexlist[indexvalue][0],data,scale)\n",
    "\n",
    "\n",
    "        else:\n",
    "            for j in range(len(r)):\n",
    "                if checklight:\n",
    "                    if r[j] <=rcheck and (i.pflux*scale <= 0.9*data.pflux[j] or i.pflux*scale>=1.1*data.pflux[j]):\n",
    "                        indexlist.append(j)\n",
    "                        if i.id not in savedilist:\n",
    "                            FluxVar(vars(i),j,data,scale)\n",
    "                            savedilist.append(i.id)\n",
    "                    elif r[j] <=rcheck:\n",
    "                        indexlist.append(j)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "                    if r[j] <=rcheck:\n",
    "                        indexlist.append(j)\n",
    "\n",
    "        masterindex.append(indexlist)\n",
    "    \n",
    "#     check if thereis a zero listentry in masterindex.. if so append it to the varying pos sources class.\n",
    "    i = 0\n",
    "    while i < len(masterindex):\n",
    "        if not masterindex[i]:\n",
    "            PosVar(vars(sources[i]),data)\n",
    "        i+=1\n",
    "\n",
    "    print 'after:'  \n",
    "    print str(len(PosVar.instances)) +\" Interesting candidates\"\n",
    "    print str(len(FluxVar.instances)) + \" Flux Varying candidates\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class object for saving our candidate transients, class object for storing objects that have varying flux compared to external database and\n",
    "Initialize our transients class and other banana sources lists.\n",
    "\n",
    "(This piece of code has to be rerun everytime you adjust something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Transients(object):\n",
    "    instances = []\n",
    "    def __init__(self,ra,rae,dec,dece,ids,pflux,pfluxe,url):\n",
    "        self.id = ids\n",
    "        y = np.stack((ra,dec),axis = -1)\n",
    "        self.url = url\n",
    "        self.ra = ra\n",
    "        self.rae = rae\n",
    "        self.dec = dec\n",
    "        self.dece = dece\n",
    "        self.pflux = pflux\n",
    "        self.pfluxe = pfluxe\n",
    "        self.freq = 144\n",
    "        self.keys = ['yoloswag']\n",
    "        self.radec = np.reshape(y,(1,2))\n",
    "        c = SkyCoord(self.ra, self.dec, frame='fk5', unit='deg')\n",
    "        self.fk5 = c.to_string('hmsdms',sep=' ',precision= 0)\n",
    "        self.c = c\n",
    "        Transients.instances.append(self)\n",
    "\n",
    "    def DelFalse(i):\n",
    "        del Transients.instances[i]\n",
    "\n",
    "class PosVar(object):\n",
    "    \"\"\"class object for storing objects that have a varying position compared to the database we are looking in\"\"\"\n",
    "    instances = []\n",
    "    def __init__(self,params,database):\n",
    "        self.id = params['id']            \n",
    "        self.ra = params['ra']\n",
    "        self.url = params['url']\n",
    "        self.database = database\n",
    "        self.dataname = database.name\n",
    "        self.dec = params['dec']\n",
    "        self.radec = params['radec']\n",
    "        self.pflux = params['pflux']\n",
    "        c = SkyCoord(params['ra'], params['dec'], frame='fk5', unit='deg')\n",
    "        self.fk5 = c.to_string('hmsdms',sep=' ',precision= 0)\n",
    "        self.c = c\n",
    "        try:\n",
    "            self.iflux = params['iflux']\n",
    "        except:\n",
    "            pass\n",
    "        PosVar.instances.append(self)\n",
    "        \n",
    "\n",
    "class TestInstance(object):\n",
    "    \"\"\"class object for storing objects that have a varying position compared to the database we are looking in\"\"\"\n",
    "    instances = []\n",
    "    def __init__(self,params):\n",
    "        self.id = params['id']            \n",
    "        self.ra = params['ra']\n",
    "        self.url = params['url']\n",
    "        self.database = params['database']\n",
    "        self.dataname = params['dataname']\n",
    "        self.dec = params['dec']\n",
    "        self.radec = params['radec']\n",
    "        self.pflux = params['pflux']\n",
    "        c = SkyCoord(params['ra'], params['dec'], frame='fk5', unit='deg')\n",
    "        self.fk5 = c.to_string('hmsdms',sep=' ',precision= 0)\n",
    "        self.c = c\n",
    "        try:\n",
    "            self.iflux = params['iflux']\n",
    "        except:\n",
    "            pass\n",
    "        TestInstance.instances.append(self)\n",
    "        \n",
    "class SavedFluxSources(object):\n",
    "    \"\"\"class object for storing objects that have a varying position compared to the database we are looking in\"\"\"\n",
    "    instances = []\n",
    "    def __init__(self,initialid,initialpflux,initialpfluxerr,params):\n",
    "        self.id = params['id']            \n",
    "        self.ra = params['ra']\n",
    "        self.url = params['url']\n",
    "        self.dec = params['dec']\n",
    "        self.rae = params['rae']\n",
    "        self.dece = params['dece']\n",
    "        self.radec = params['radec']\n",
    "        self.pflux = params['pflux']\n",
    "        self.freq = params['freq']\n",
    "        self.pfluxe = params['pfluxe']\n",
    "        c = SkyCoord(params['ra'], params['dec'], frame='fk5', unit='deg')\n",
    "        self.fk5 = c.to_string('hmsdms',sep=' ',precision= 0)\n",
    "        self.c = c\n",
    "        self.cmpid = initialid\n",
    "        self.cmppflux = initialpflux\n",
    "        self.cmppfluxerr = initialpfluxerr\n",
    "        try:\n",
    "            self.iflux = params['iflux']\n",
    "        except:\n",
    "            pass\n",
    "        SavedFluxSources.instances.append(self)\n",
    "\n",
    "class SavedPosSources(object):\n",
    "    \"\"\"class object for storing objects that have a varying position compared to the database we are looking in\"\"\"\n",
    "    instances = []\n",
    "    def __init__(self,params):\n",
    "        self.id = params['id']            \n",
    "        self.ra = params['ra']\n",
    "        self.url = params['url']\n",
    "        self.dec = params['dec']\n",
    "        self.rae = params['rae']\n",
    "        self.dece = params['dece']\n",
    "        self.radec = params['radec']\n",
    "        self.pflux = params['pflux']\n",
    "        self.freq = params['freq']\n",
    "        self.pfluxe = params['pfluxe']\n",
    "        c = SkyCoord(params['ra'], params['dec'], frame='fk5', unit='deg')\n",
    "        self.fk5 = c.to_string('hmsdms',sep=' ',precision= 0)\n",
    "        self.c = c\n",
    "        try:\n",
    "            self.iflux = params['iflux']\n",
    "        except:\n",
    "            pass\n",
    "        SavedPosSources.instances.append(self)  \n",
    "    \n",
    "class FluxVar(object):\n",
    "    \"\"\"class object for storing objects that have a varying flux compared to the database we are looking in\"\"\"\n",
    "    instances = []\n",
    "    def __init__(self,params,databaseentry,database,scale):\n",
    "        self.id = params['id']\n",
    "        self.ra = params['ra']\n",
    "        self.url = params['url']\n",
    "        self.database = database\n",
    "        self.dataname = database.name\n",
    "        self.scale = scale\n",
    "        self.dec = params['dec']\n",
    "        self.radec = params['radec']\n",
    "        self.pflux = params['pflux']\n",
    "        self.entry = databaseentry\n",
    "        c = SkyCoord(params['ra'], params['dec'], frame='fk5', unit='deg')\n",
    "        self.fk5 = c.to_string('hmsdms',sep=' ',precision= 0)\n",
    "        self.c = c\n",
    "        c = c.icrs\n",
    "        self.icrs = c.to_string('hmsdms',sep=' ',precision= 0)\n",
    "        try:\n",
    "            self.iflux = params['iflux']\n",
    "        except:\n",
    "            pass\n",
    "        FluxVar.instances.append(self)\n",
    "    \n",
    "\n",
    "        \n",
    "racata = []\n",
    "raecata = []\n",
    "deccata = []\n",
    "dececata = []\n",
    "idcata = []\n",
    "lightcata = []\n",
    "lightecata = []\n",
    "idstorelist = []\n",
    "for i in range(len(plotdata)):\n",
    "    if plotdata[i][0] in idstorelist:\n",
    "        continue\n",
    "    else:\n",
    "        if plotdata[i][6] == 0:\n",
    "            Transients(plotdata[i][1],plotdata[i][3],plotdata[i][2],plotdata[i][4],plotdata[i][0],fpeak[plotdata[i][9]-1][0],fpeake[plotdata[i][9]-1][0],[plotdata[i][11]])\n",
    "            idstorelist.append(plotdata[i][0])\n",
    "        else:\n",
    "            racata.append(plotdata[i][1])\n",
    "            raecata.append(plotdata[i][3])\n",
    "            deccata.append(plotdata[i][2])\n",
    "            dececata.append(plotdata[i][4])\n",
    "            idcata.append(plotdata[i][0])\n",
    "#           -1 necessary to account for pythonic lists\n",
    "            lightcata.append(fpeak[plotdata[i][9]-1][0])\n",
    "            lightecata.append(fpeake[plotdata[i][9]-1][0])\n",
    "        \n",
    "X = np.stack((racata,deccata),axis = -1)\n",
    "\n",
    "racata = np.array(racata)\n",
    "raecata = np.array(raecata)\n",
    "dececata = np.array(dececata)\n",
    "deccata = np.array(deccata)\n",
    "idcata = np.array(idcata)\n",
    "lightcata = np.array(lightcata)\n",
    "lightecata = np.array(lightecata)\n",
    "# for i in Transients.instances:\n",
    "#     print i.id\n",
    "print idstorelist\n",
    "for i in plotdata:\n",
    "    print i[6]\n",
    "print plotdata[1][6]\n",
    "# Transients(183,0.01,45,0.01,99999999,1.32,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasl = []\n",
    "# raesl = []\n",
    "# decsl = []\n",
    "# decesl = []\n",
    "# idsl = []\n",
    "# pfluxsl = []\n",
    "# pfluxesl = []\n",
    "# for i in range(len(plotdata)):\n",
    "#     rasl.append(plotdata[i][1])\n",
    "#     raesl.append(plotdata[i][3])\n",
    "#     decsl.append(plotdata[i][2])\n",
    "#     decesl.append(plotdata[i][4])\n",
    "#     idsl.append(plotdata[i][0])\n",
    "#     pfluxsl.append(fpeak[plotdata[i][9]-1][0])\n",
    "#     pfluxesl.append(fpeake[plotdata[i][9]-1][0])\n",
    "\n",
    "\n",
    "\n",
    "# raseries = pd.Series(racata)\n",
    "# raseries\n",
    "# ras = pd.Series(rasl, name='ra')\n",
    "# raes = pd.Series(raesl, name='raerr')\n",
    "# decs = pd.Series(decsl, name='dec')\n",
    "# deces = pd.Series(decesl, name='decerr')\n",
    "# ids = pd.Series(idsl, name='id')\n",
    "# pfluxs = pd.Series(pfluxsl, name='pflux')\n",
    "# pfluxes = pd.Series(pfluxesl, name='pfluxerr')\n",
    "\n",
    "# pandacata = pd.concat([ras, raes,decs,deces,ids,pfluxs,pfluxes], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we call the function for calculating the de ruiter distance between candidates and our found sources and if True is given we also check if the max of the lightcurve of the sources compared fall withing 5 sigma flux of each other (thus making it increasingly likely for   the source to be a sidelobe)\n",
    "\n",
    "This extra flux comparison is used in order to not potentially write of a faint or bright transient close to a known source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectorForCandidateslist(rcheck,ycheck,checklight,deruiter=True):\n",
    "    \"\"\"Function for pruning the candidate list using both distance and lightcurve measurements\"\"\"\n",
    "    ctr = 0\n",
    "    print 'before:'\n",
    "    print len(Transients.instances)\n",
    "    oldlen = len(Transients.instances) + 1\n",
    "    savedinitiallength = len(Transients.instances)\n",
    "    \n",
    "# #   Repeat until no improvement in the length of the candidate list\n",
    "#     while len(Transients.instances) - oldlen < 0:\n",
    "    ratlist = []\n",
    "    detclist = []\n",
    "\n",
    "    translist = []\n",
    "#         rlist = []\n",
    "    oldlen = len(Transients.instances)\n",
    "\n",
    "#         These lists are necessary to compare the candidate Transientss against each other\n",
    "    ralist = []\n",
    "    raelist = []\n",
    "    declist = []\n",
    "    decelist = []\n",
    "\n",
    "# \"\"\"Check candidate Transientss against each other\"\"\"\n",
    "\n",
    "    for h in Transients.instances:\n",
    "        if not deruiter:\n",
    "            translist.append(h.radec)\n",
    "        else:\n",
    "            ralist.append(h.ra)\n",
    "            raelist.append(h.rae)\n",
    "            declist.append(h.dec)\n",
    "            decelist.append(h.dece)\n",
    "            \n",
    "\n",
    "    masterindex = []\n",
    "    savedlist = []\n",
    "    first = True\n",
    "    for i in Transients.instances:\n",
    "        nocount = False\n",
    "        indexlist = []\n",
    "\n",
    "\n",
    "\n",
    "        r = CalcDeRuiter(vars(i),np.array(ralist),\\\n",
    "        np.array(raelist),np.array(declist),np.array(decelist))\n",
    "        y = CompareFluxes(vars(i),np.array(lightcata),np.array(lightecata))\n",
    "        for j in range(len(r)):\n",
    "\n",
    "            if r[j] <=rcheck and r[j]!=0.0:\n",
    "                indexlist.append(j)\n",
    "                nocount = True\n",
    "                        \n",
    "#         SAVE ENTRIES THAT HAVE A BIG DIFFERENCE ON FLUX\n",
    "        if checklight:\n",
    "            pfluxlist = []\n",
    "            pfluxelist = []\n",
    "            for z in indexlist:            \n",
    "                pfluxlist.append(Transients.instances[z].pflux)\n",
    "                pfluxelist.append(Transients.instances[z].pfluxe)\n",
    "\n",
    "            y = CompareFluxes(vars(i),np.array(pfluxlist),np.array(pfluxelist))\n",
    "            \n",
    "            if first:\n",
    "                print y\n",
    "                first = False\n",
    "                try:\n",
    "                    print Transients.instances[indexlist[0]].id\n",
    "                except:\n",
    "                    pass\n",
    "            for o in range(len(y)):\n",
    "                if y[o]>=ycheck:\n",
    "                    SavedFluxSources(i.id,i.pflux,i.pfluxe,vars(Transients.instances[indexlist[o]]))\n",
    "                    break\n",
    "                    \n",
    "                 \n",
    "#         DELETE DOUBLE ENTRIES reform lists\n",
    "        if nocount:\n",
    "            k = 0\n",
    "            g = 0\n",
    "            while k < len(indexlist):\n",
    "                del Transients.instances[indexlist[k]-g]\n",
    "\n",
    "                k+=1\n",
    "                g+=1\n",
    "\n",
    "            ralist = []\n",
    "            raelist = []\n",
    "            declist = []\n",
    "            decelist = []\n",
    "\n",
    "            for h in Transients.instances:\n",
    "                ralist.append(h.ra)\n",
    "                raelist.append(h.rae)\n",
    "                declist.append(h.dec)\n",
    "                decelist.append(h.dece)\n",
    "\n",
    "\n",
    "    print 'after:'\n",
    "#     add back the no duplicate detections\n",
    "#     for i in SavedPosSources.instances:\n",
    "#         TestInstance(vars(i))\n",
    "    print len(Transients.instances)\n",
    "    print len(SavedFluxSources.instances)\n",
    "    return str(len(Transients.instances)), savedinitiallength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initialselector,initiallenghtcandi = SelectorForCandidateslist(rcheck = 5, ycheck = 5,checklight = True, deruiter = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print out in latex format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print SavedFluxSources.instances[1].pflux\n",
    "    print Transients.instances[1].pflux\n",
    "except:\n",
    "    pass\n",
    "FluxVar.instances = []\n",
    "PosVar.instances = []\n",
    "for i in Transients.instances:\n",
    "    print i.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsbase.WriteFluxJson('tgss','185.28 48.62','1283')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-26 19:27:26 [scrapy.utils.log] INFO: Scrapy 1.7.3 started (bot: scrapybot)\n",
      "2019-08-26 19:27:26 [scrapy.utils.log] INFO: Versions: lxml 4.4.0.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.2.1, Python 2.7.12 (default, Jan  9 2017, 12:16:27) - [GCC 4.8.4], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Linux-3.13.0-147-generic-x86_64-with-Ubuntu-14.04-trusty\n",
      "2019-08-26 19:27:26 [scrapy.crawler] INFO: Overridden settings: {'SPIDER_LOADER_WARN_ONLY': True, 'FEED_FORMAT': 'json', 'FEED_URI': 'tgssscraped.json'}\n",
      "2019-08-26 19:27:26 [scrapy.extensions.telnet] INFO: Telnet Password: 6b579f138822a499\n",
      "2019-08-26 19:27:26 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.corestats.CoreStats']\n",
      "2019-08-26 19:27:26 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-08-26 19:27:26 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-08-26 19:27:26 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-08-26 19:27:26 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-08-26 19:27:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-08-26 19:27:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "{u'url': u'https://vo.astron.nl/tgssadr/q/cone/form', u'pos': u'185.28 48.62', u'hsize': u'1283', u'name': u'tgss'}\n",
      "https://vo.astron.nl/tgssadr/q/cone/form\n",
      "2019-08-26 19:27:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://vo.astron.nl/tgssadr/q/cone/form> (referer: None)\n",
      "2019-08-26 19:27:26 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://vo.astron.nl/tgssadr/q/cone/form> (referer: https://vo.astron.nl/tgssadr/q/cone/form)\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'0.0', 'rae': u'2.00', 'dist': u'5.48', 'majax': u'29.9', 's_code': u'M', 'dece': u'2.00', 'sint': u'2264.5', 'pa': u'-21.5', 'majaxe': u'0.1', 'island_rms': u'3.4', 'spke': u'205.7', 'spk': u'2057.2', 'ra': u'185.29494', 'mosaic_name': u'R38D63', 'minax': u'26.0', 'dec': u'48.71078', 'id': u'J122110.7+484238', 'sinte': u'226.6', 'pae': u'0.6'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'2.3', 'rae': u'2.30', 'dist': u'5.55', 'majax': u'29.9', 's_code': u'S', 'dece': u'2.20', 'sint': u'57.1', 'pa': u'-59.6', 'majaxe': u'2.6', 'island_rms': u'3.4', 'spke': u'5.6', 'spk': u'42.9', 'ra': u'185.23462', 'mosaic_name': u'R38D63', 'minax': u'27.8', 'dec': u'48.70758', 'id': u'J122056.3+484227', 'sinte': u'8.1', 'pae': u'47.3'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'2.7', 'rae': u'2.30', 'dist': u'7.24', 'majax': u'29.1', 's_code': u'S', 'dece': u'2.50', 'sint': u'37.7', 'pa': u'3.3', 'majaxe': u'3.5', 'island_rms': u'3.5', 'spke': u'4.8', 'spk': u'31.6', 'ra': u'185.12428', 'mosaic_name': u'R38D63', 'minax': u'25.6', 'dec': u'48.68299', 'id': u'J122029.8+484058', 'sinte': u'7.0', 'pae': u'37.7'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'1.5', 'rae': u'2.10', 'dist': u'11.05', 'majax': u'26.9', 's_code': u'S', 'dece': u'2.10', 'sint': u'61.2', 'pa': u'-12.3', 'majaxe': u'1.7', 'island_rms': u'3.4', 'spke': u'6.7', 'spk': u'56.8', 'ra': u'185.50494', 'mosaic_name': u'R38D63', 'minax': u'25.0', 'dec': u'48.51150', 'id': u'J122201.1+483041', 'sinte': u'8.5', 'pae': u'35.8'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'2.4', 'rae': u'2.40', 'dist': u'12.12', 'majax': u'29.0', 's_code': u'S', 'dece': u'2.30', 'sint': u'40.5', 'pa': u'77.3', 'majaxe': u'3.1', 'island_rms': u'3.4', 'spke': u'4.9', 'spk': u'34.5', 'ra': u'185.20053', 'mosaic_name': u'R38D63', 'minax': u'25.3', 'dec': u'48.81509', 'id': u'J122048.1+484854', 'sinte': u'7.0', 'pae': u'31.6'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'0.8', 'rae': u'2.00', 'dist': u'12.47', 'majax': u'31.6', 's_code': u'S', 'dece': u'2.00', 'sint': u'163.8', 'pa': u'80.0', 'majaxe': u'1.0', 'island_rms': u'3.4', 'spke': u'12.4', 'spk': u'118.0', 'ra': u'185.07571', 'mosaic_name': u'R38D63', 'minax': u'27.4', 'dec': u'48.77825', 'id': u'J122018.1+484641', 'sinte': u'17.3', 'pae': u'9.5'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'1.7', 'rae': u'2.80', 'dist': u'13.43', 'majax': u'54.0', 's_code': u'S', 'dece': u'2.10', 'sint': u'118.4', 'pa': u'-87.6', 'majaxe': u'4.6', 'island_rms': u'3.4', 'spke': u'5.9', 'spk': u'47.9', 'ra': u'185.28944', 'mosaic_name': u'R38D63', 'minax': u'28.6', 'dec': u'48.84383', 'id': u'J122109.4+485037', 'sinte': u'12.7', 'pae': u'6.9'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'1.9', 'rae': u'2.20', 'dist': u'15.75', 'majax': u'28.6', 's_code': u'S', 'dece': u'2.20', 'sint': u'53.4', 'pa': u'-34.5', 'majaxe': u'2.3', 'island_rms': u'3.4', 'spke': u'5.7', 'spk': u'45.3', 'ra': u'184.88280', 'mosaic_name': u'R38D63', 'minax': u'25.8', 'dec': u'48.62031', 'id': u'J121931.8+483713', 'sinte': u'7.9', 'pae': u'32.3'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'1.2', 'rae': u'2.10', 'dist': u'17.61', 'majax': u'44.7', 's_code': u'C', 'dece': u'2.20', 'sint': u'226.3', 'pa': u'7.9', 'majaxe': u'1.9', 'island_rms': u'3.4', 'spke': u'10.0', 'spk': u'93.3', 'ra': u'184.99043', 'mosaic_name': u'R38D63', 'minax': u'33.9', 'dec': u'48.39783', 'id': u'J121957.7+482352', 'sinte': u'23.2', 'pae': u'7.0'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'2.6', 'rae': u'2.30', 'dist': u'18.50', 'majax': u'39.4', 's_code': u'C', 'dece': u'2.40', 'sint': u'105.5', 'pa': u'7.2', 'majaxe': u'3.2', 'island_rms': u'3.4', 'spke': u'6.1', 'spk': u'48.4', 'ra': u'184.98528', 'mosaic_name': u'R38D63', 'minax': u'34.5', 'dec': u'48.38137', 'id': u'J121956.4+482252', 'sinte': u'11.8', 'pae': u'25.8'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'2.4', 'rae': u'2.90', 'dist': u'20.71', 'majax': u'52.1', 's_code': u'S', 'dece': u'3.20', 'sint': u'66.0', 'pa': u'39.0', 'majaxe': u'7.3', 'island_rms': u'3.3', 'spke': u'4.5', 'spk': u'29.8', 'ra': u'185.62605', 'mosaic_name': u'R38D63', 'minax': u'26.6', 'dec': u'48.87910', 'id': u'J122230.2+485244', 'sinte': u'8.1', 'pae': u'10.5'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'0.1', 'rae': u'2.00', 'dist': u'21.24', 'majax': u'26.2', 's_code': u'S', 'dece': u'2.00', 'sint': u'846.9', 'pa': u'70.2', 'majaxe': u'0.1', 'island_rms': u'3.4', 'spke': u'78.8', 'spk': u'787.4', 'ra': u'184.77725', 'mosaic_name': u'R38D63', 'minax': u'25.6', 'dec': u'48.49908', 'id': u'J121906.5+482956', 'sinte': u'84.9', 'pae': u'7.7'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'1.4', 'rae': u'2.10', 'dist': u'30.85', 'majax': u'27.7', 's_code': u'S', 'dece': u'2.10', 'sint': u'69.0', 'pa': u'15.1', 'majaxe': u'1.7', 'island_rms': u'3.5', 'spke': u'7.2', 'spk': u'62.0', 'ra': u'185.11792', 'mosaic_name': u'R38D63', 'minax': u'25.1', 'dec': u'48.11719', 'id': u'J122028.3+480701', 'sinte': u'9.2', 'pae': u'25.4'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'1.0', 'rae': u'2.00', 'dist': u'32.10', 'majax': u'36.6', 's_code': u'S', 'dece': u'2.10', 'sint': u'172.4', 'pa': u'7.4', 'majaxe': u'1.5', 'island_rms': u'3.4', 'spke': u'10.5', 'spk': u'97.9', 'ra': u'185.88348', 'mosaic_name': u'R38D63', 'minax': u'30.1', 'dec': u'48.97815', 'id': u'J122332.0+485841', 'sinte': u'18.1', 'pae': u'9.4'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'0.8', 'rae': u'2.00', 'dist': u'32.42', 'majax': u'36.5', 's_code': u'C', 'dece': u'2.10', 'sint': u'141.6', 'pa': u'16.1', 'majaxe': u'1.6', 'island_rms': u'3.5', 'spke': u'10.3', 'spk': u'95.6', 'ra': u'185.04614', 'mosaic_name': u'R38D63', 'minax': u'25.4', 'dec': u'48.10249', 'id': u'J122011.0+480608', 'sinte': u'15.3', 'pae': u'5.3'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'1.2', 'rae': u'2.10', 'dist': u'32.61', 'majax': u'36.1', 's_code': u'S', 'dece': u'2.20', 'sint': u'88.9', 'pa': u'-23.4', 'majaxe': u'2.3', 'island_rms': u'3.1', 'spke': u'6.9', 'spk': u'60.4', 'ra': u'185.60567', 'mosaic_name': u'R38D63', 'minax': u'25.5', 'dec': u'48.12142', 'id': u'J122225.3+480717', 'sinte': u'10.3', 'pae': u'8.2'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'3.6', 'rae': u'2.60', 'dist': u'32.94', 'majax': u'27.9', 's_code': u'S', 'dece': u'2.50', 'sint': u'29.5', 'pa': u'71.5', 'majaxe': u'3.8', 'island_rms': u'3.2', 'spke': u'4.1', 'spk': u'24.5', 'ra': u'184.55438', 'mosaic_name': u'R38D63', 'minax': u'26.9', 'dec': u'48.88924', 'id': u'J121813.0+485321', 'sinte': u'6.2', 'pae': u'90.0'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'0.3', 'rae': u'2.00', 'dist': u'33.22', 'majax': u'27.1', 's_code': u'C', 'dece': u'2.00', 'sint': u'365.1', 'pa': u'2.8', 'majaxe': u'0.3', 'island_rms': u'3.5', 'spke': u'32.2', 'spk': u'319.7', 'ra': u'185.04582', 'mosaic_name': u'R38D63', 'minax': u'26.3', 'dec': u'48.08864', 'id': u'J122010.9+480519', 'sinte': u'37.0', 'pae': u'15.1'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'1.0', 'rae': u'2.10', 'dist': u'33.81', 'majax': u'28.7', 's_code': u'S', 'dece': u'2.10', 'sint': u'113.5', 'pa': u'42.1', 'majaxe': u'1.2', 'island_rms': u'3.5', 'spke': u'9.9', 'spk': u'91.8', 'ra': u'186.02708', 'mosaic_name': u'R38D63', 'minax': u'26.9', 'dec': u'48.89381', 'id': u'J122406.5+485337', 'sinte': u'12.8', 'pae': u'26.9'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'2.7', 'rae': u'2.60', 'dist': u'33.82', 'majax': u'33.3', 's_code': u'S', 'dece': u'2.30', 'sint': u'46.5', 'pa': u'-85.1', 'majaxe': u'3.8', 'island_rms': u'3.1', 'spke': u'4.6', 'spk': u'31.6', 'ra': u'184.46693', 'mosaic_name': u'R38D63', 'minax': u'27.6', 'dec': u'48.45319', 'id': u'J121752.0+482711', 'sinte': u'6.9', 'pae': u'25.2'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'2.2', 'rae': u'2.20', 'dist': u'34.33', 'majax': u'25.8', 's_code': u'S', 'dece': u'2.20', 'sint': u'36.2', 'pa': u'35.9', 'majaxe': u'2.3', 'island_rms': u'3.1', 'spke': u'4.7', 'spk': u'35.0', 'ra': u'185.68660', 'mosaic_name': u'R38D63', 'minax': u'25.0', 'dec': u'48.11554', 'id': u'J122244.7+480655', 'sinte': u'6.5', 'pae': u'90.0'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'0.4', 'rae': u'2.00', 'dist': u'34.51', 'majax': u'27.7', 's_code': u'S', 'dece': u'2.00', 'sint': u'272.8', 'pa': u'44.3', 'majaxe': u'0.4', 'island_rms': u'3.4', 'spke': u'23.9', 'spk': u'236.1', 'ra': u'184.74792', 'mosaic_name': u'R38D63', 'minax': u'26.0', 'dec': u'48.16621', 'id': u'J121859.5+480958', 'sinte': u'27.9', 'pae': u'9.7'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'0.2', 'rae': u'2.00', 'dist': u'37.34', 'majax': u'26.2', 's_code': u'S', 'dece': u'2.00', 'sint': u'472.0', 'pa': u'-22.2', 'majaxe': u'0.2', 'island_rms': u'3.0', 'spke': u'44.6', 'spk': u'444.9', 'ra': u'185.99300', 'mosaic_name': u'R38D63', 'minax': u'25.4', 'dec': u'48.21588', 'id': u'J122358.3+481257', 'sinte': u'47.5', 'pae': u'9.8'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'0.7', 'rae': u'2.10', 'dist': u'38.31', 'majax': u'40.4', 's_code': u'M', 'dece': u'2.00', 'sint': u'288.1', 'pa': u'31.0', 'majaxe': u'1.4', 'island_rms': u'3.5', 'spke': u'14.0', 'spk': u'136.0', 'ra': u'185.05557', 'mosaic_name': u'R38D63', 'minax': u'27.7', 'dec': u'47.99916', 'id': u'J122013.3+475956', 'sinte': u'29.9', 'pae': u'3.9'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://vo.astron.nl/tgssadr/q/cone/form>\n",
      "{'minaxe': u'1.8', 'rae': u'2.20', 'dist': u'38.66', 'majax': u'26.8', 's_code': u'S', 'dece': u'2.20', 'sint': u'44.0', 'pa': u'36.0', 'majaxe': u'2.3', 'island_rms': u'3.5', 'spke': u'5.6', 'spk': u'43.1', 'ra': u'184.94899', 'mosaic_name': u'R38D63', 'minax': u'23.8', 'dec': u'48.01446', 'id': u'J121947.7+480052', 'sinte': u'7.5', 'pae': u'30.1'}\n",
      "2019-08-26 19:27:27 [scrapy.core.scraper] ERROR: Spider error processing <POST https://vo.astron.nl/tgssadr/q/cone/form> (referer: https://vo.astron.nl/tgssadr/q/cone/form)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/antoniar/virtenv/local/lib/python2.7/site-packages/scrapy/utils/defer.py\", line 102, in iter_errback\n",
      "    yield next(it)\n",
      "  File \"/home/antoniar/virtenv/local/lib/python2.7/site-packages/scrapy/core/spidermw.py\", line 84, in evaluate_iterable\n",
      "    for r in iterable:\n",
      "  File \"/home/antoniar/virtenv/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/offsite.py\", line 29, in process_spider_output\n",
      "    for x in result:\n",
      "  File \"/home/antoniar/virtenv/local/lib/python2.7/site-packages/scrapy/core/spidermw.py\", line 84, in evaluate_iterable\n",
      "    for r in iterable:\n",
      "  File \"/home/antoniar/virtenv/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/referer.py\", line 339, in <genexpr>\n",
      "    return (_set_referer(r) for r in result or ())\n",
      "  File \"/home/antoniar/virtenv/local/lib/python2.7/site-packages/scrapy/core/spidermw.py\", line 84, in evaluate_iterable\n",
      "    for r in iterable:\n",
      "  File \"/home/antoniar/virtenv/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/urllength.py\", line 37, in <genexpr>\n",
      "    return (r for r in result or () if _filter(r))\n",
      "  File \"/home/antoniar/virtenv/local/lib/python2.7/site-packages/scrapy/core/spidermw.py\", line 84, in evaluate_iterable\n",
      "    for r in iterable:\n",
      "  File \"/home/antoniar/virtenv/local/lib/python2.7/site-packages/scrapy/spidermiddlewares/depth.py\", line 58, in <genexpr>\n",
      "    return (r for r in result or () if _filter(r))\n",
      "  File \"/home/kmeulen/notebooks/GoodKrieksTools/KrieksNotebook/KrieksTransients/databaseanalyzer.py\", line 40, in parse\n",
      "    dist = data[0]\n",
      "IndexError: list index out of range\n",
      "2019-08-26 19:27:27 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-08-26 19:27:27 [scrapy.extensions.feedexport] INFO: Stored json feed (25 items) in: tgssscraped.json\n",
      "2019-08-26 19:27:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 708,\n",
      " 'downloader/request_count': 2,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/request_method_count/POST': 1,\n",
      " 'downloader/response_bytes': 15273,\n",
      " 'downloader/response_count': 2,\n",
      " 'downloader/response_status_count/200': 2,\n",
      " 'elapsed_time_seconds': 0.62432,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 8, 26, 17, 27, 27, 120787),\n",
      " 'item_scraped_count': 25,\n",
      " 'log_count/DEBUG': 27,\n",
      " 'log_count/ERROR': 1,\n",
      " 'log_count/INFO': 11,\n",
      " 'memusage/max': 47894528,\n",
      " 'memusage/startup': 47894528,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 2,\n",
      " 'scheduler/dequeued': 2,\n",
      " 'scheduler/dequeued/memory': 2,\n",
      " 'scheduler/enqueued': 2,\n",
      " 'scheduler/enqueued/memory': 2,\n",
      " 'spider_exceptions/IndexError': 1,\n",
      " 'start_time': datetime.datetime(2019, 8, 26, 17, 27, 26, 496467)}\n",
      "2019-08-26 19:27:27 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    os.remove('tgssscraped.json')\n",
    "except:\n",
    "    print 'allready removed'\n",
    "\n",
    "!{sys.executable} -m scrapy runspider databaseanalyzer.py -o tgssscraped.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'dec', u'dece', u'dist', u'id', u'island_rms', u'majax', u'majaxe',\n",
       "       u'minax', u'minaxe', u'mosaic_name', u'pa', u'pae', u'ra', u'rae',\n",
       "       u's_code', u'sint', u'sinte', u'spk', u'spke'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tgss = ljs.Loadin('tgssscraped')\n",
    "tgss.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2264.5\n",
       "1       57.1\n",
       "2       37.7\n",
       "3       61.2\n",
       "4       40.5\n",
       "5      163.8\n",
       "6      118.4\n",
       "7       53.4\n",
       "8      226.3\n",
       "9      105.5\n",
       "10      66.0\n",
       "11     846.9\n",
       "12      69.0\n",
       "13     172.4\n",
       "14     141.6\n",
       "15      88.9\n",
       "16      29.5\n",
       "17     365.1\n",
       "18     113.5\n",
       "19      46.5\n",
       "20      36.2\n",
       "21     272.8\n",
       "22     472.0\n",
       "23     288.1\n",
       "24      44.0\n",
       "Name: sint, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgssra = tgss.ra.astype(float)\n",
    "tgssrae = tgss.rae.astype(float)\n",
    "tgssdec = tgss.dec.astype(float)\n",
    "tgssdece = tgss.dece.astype(float)\n",
    "tgsssint = tgss.sint.astype(float)\n",
    "tgsssinte = tgss.sinte.astype(float)\n",
    "tgsssint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class datawrapp(object):\n",
    "    def __init__(self,name,ra,rae,dec,dece,pflux,pfluxe,freq):\n",
    "\n",
    "        self.radec = np.stack((ra,dec),axis = -1)\n",
    "        self.ra = ra\n",
    "        self.name = name\n",
    "        if name == \"tgss\":\n",
    "            self.rae = rae/3600\n",
    "        elif name == 'vlssr':\n",
    "            self.rae = np.full(np.shape(ra),0.00333333)\n",
    "        else:\n",
    "            self.rae = rae\n",
    "        self.dec = dec\n",
    "        if self.name == \"tgss\":\n",
    "            print pflux\n",
    "            self.dece = dece/3600\n",
    "        elif name == 'vlssr':\n",
    "            self.dece = np.full(np.shape(dec),0.00333333)\n",
    "        else:\n",
    "            self.dece = dece\n",
    "        self.pflux = pflux\n",
    "        self.pfluxe = pfluxe\n",
    "        self.freq = freq\n",
    "        self.keys = ['name','radec','ra','rae','dec','dece','pflux','pfluxe','freq']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2645 0.0571 0.0377 0.0612 0.0405 0.1638 0.1184 0.0534 0.2263 0.1055\n",
      " 0.066  0.8469 0.069  0.1724 0.1416 0.0889 0.0295 0.3651 0.1135 0.0465\n",
      " 0.0362 0.2728 0.472  0.2881 0.044 ]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'unicode' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-9280d7a4d179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset = datawrapp(\"tgss\",np.array(tgssra),np.array(tgssrae),                    np.array(tgssdec),np.array(tgss.dece), #                  np.array(data.Spk/1000.),np.array(data.e_Spk/1000.)\\\n\u001b[1;32m      2\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgsssint\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgsssinte\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     ,147.5)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-b2c9f7434c35>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, ra, rae, dec, dece, pflux, pfluxe, freq)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tgss\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mpflux\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdece\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdece\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'vlssr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdece\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.00333333\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'unicode' and 'int'"
     ]
    }
   ],
   "source": [
    "dataset = datawrapp(\"tgss\",np.array(tgssra),np.array(tgssrae),\\\n",
    "                    np.array(tgssdec),np.array(tgss.dece),\\\n",
    " #                  np.array(data.Spk/1000.),np.array(data.e_Spk/1000.)\\\n",
    "                    np.array(tgsssint/1000.),np.array(tgsssinte/1000.)\\\n",
    "                    ,147.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tgss \n",
    "is the object which has tggs survey data for the field of P23 loaded into it.\n",
    "could probably just automate it here but lets leave it for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'radec', 'ra', 'rae', 'dec', 'dece', 'pflux', 'pfluxe', 'freq']\n",
      "147.5\n",
      "tgss\n",
      "98604\n",
      "0.0006028485434442595\n"
     ]
    }
   ],
   "source": [
    "tgsslist = dl.ReadData(\"tgss\")\n",
    "tgss = tgsslist[1]\n",
    "print tgss.keys\n",
    "print tgss.freq\n",
    "print tgss.name\n",
    "print len(tgss.ra)\n",
    "print np.mean(tgss.rae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CheckSimOutsideDatabase(tgss,Transients.instances,rcheck = 3,ycheck = 3,\\\n",
    "                     checklight = True, gamma = True,Cali = True,deruiter = True,euccutoff = .06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print Transients.instances[0].fk5\n",
    "print Transients.instances[0].c\n",
    "for i in Transients.instances:\n",
    "    print i.ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VLSSr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fix the error for the vlssr data\n",
    "!{sys.executable} -m pip install xlrd \n",
    "# Probably need to pip install xlrd for excell support in pandas\n",
    "vlssr = dl.ReadData('vlssr')[0]\n",
    "\n",
    "print vlssr.keys\n",
    "print vlssr.freq\n",
    "print vlssr.ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "CheckSimOutsideDatabase(vlssr,Transients.instances,rcheck = 3 ,ycheck = 3,checklight = True,\\\n",
    "                     gamma = True,Cali=True,deruiter = True,euccutoff = 0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "savedpos = []\n",
    "savedflux = []\n",
    "print len(PosVar.instances)\n",
    "print len(FluxVar.instances)\n",
    "for i in PosVar.instances:\n",
    "    if i.id not in savedpos:\n",
    "        savedpos.append(i.id)\n",
    "for i in FluxVar.instances:\n",
    "    if i.id not in savedflux:\n",
    "        savedflux.append(i.id)\n",
    "        \n",
    "posvarcatasave = len(savedpos)\n",
    "fluxvarcatasave =  len(savedflux)\n",
    "for i in PosVar.instances:\n",
    "    print i.id\n",
    "    print i.ra\n",
    "    print i.dec\n",
    "    print i.pflux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print saved flux sources LATEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"\\\\begin{longtable}{c|c|c|c|c|c|c|c|c|c} \\n\\\n",
    "\\\\toprule \\n Id & Ra (deg) & Dec (deg) & Fk5 & Flux & Fluxerr & cmpId & cmpFlux & cmpFluxerr & Candidate? (y/n)  \\\\\\\\\\\\midrule \\n\\\\endfirsthead \\n\\\\toprule \\\n",
    "\\n Id & Ra (deg) & Dec (deg) & Fk5 & Flux & Fluxerr & cmpId & cmpFlux & cmpFluxerr & Candidate? (y/n)  \\\\\\\\\\\\midrule \\n\\\\endhead \\n\\\\bottomrule \\n\\\\endfoot \\n\\\\bottomrule\"\n",
    "\n",
    "# define caption for table\n",
    "print \"\\\\caption{ SAVED FLUX SOURCES} \\n\\\\endlastfoot\"\n",
    "for i in SavedFluxSources.instances:\n",
    "    print latexHREF + str(i.id) +\"}{%i}\" %(i.id)+ \" \" + \"&\"+ \" \" + '%0.3f' %i.ra + \" \" + \"&\"+ \" \"+ \"%0.3f\" %(i.dec) +\\\n",
    "    \" \" + \"&\" + i.fk5+\"&\" + \" \" + '%0.3f' %(i.pflux) +\"&\" + \" \" + '%0.3f' %(i.pfluxe) +\"&\" + \" \" +\\\n",
    "    latexHREF + str(i.cmpid) +\"}{%i}\" %(i.cmpid)\\\n",
    "    +\"&\" + \" \" +'%0.3f' %(i.cmppflux) +\"&\" + \" \"\\\n",
    "    + '%0.3f' %(i.cmppfluxerr) +\"&\" + \" \" +\"\\\\\" + \"\\\\\"\n",
    "print \"\\\\end{longtable}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the same position Fluxvariating sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in FluxVar.instances:\n",
    "    \n",
    "    print \"Data compared to \" + i.database.name\n",
    "    print i.id\n",
    "    print websiteURL+str(i.id)\n",
    "    print 'bananaflux: ' + str(i.pflux*i.scale)\n",
    "\n",
    "    print i.database.name+'flux: ' + str(i.database.pflux[i.entry])\n",
    "    print i.database.ra[i.entry]\n",
    "    print i.database.dec[i.entry]\n",
    "    print \"------------------------\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the same position Fluxvariating sources in Latex ready format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print \"\\\\begin{landscape}\\n\"\n",
    "# print \"\\\\section{Fluxvariating Sources}\\n\"\n",
    "# # SEPERATE DATABASES\n",
    "# databaselist = ['tgss','vlssr']\n",
    "\n",
    "# samesieslist = []\n",
    "# for i in range(len(FluxVar.instances)):\n",
    "#     samesie = False\n",
    "#     tempdict = {'tgss':None,'vlssr':None,'id':None,'ra':None,'dec':None,'fk5':None}\n",
    "    \n",
    "# #   create combined name if entry both in vlssr and tgss\n",
    "#     for j in range(len(samesieslist)):\n",
    "#         if FluxVar.instances[i].id == samesieslist[j]['id']:\n",
    "# #             samesieslist[j].append(FluxVar.instances[i])\n",
    "#             samesieslist[j][FluxVar.instances[i].database.name] = FluxVar.instances[i]\n",
    "          \n",
    "#             samesie = True\n",
    "#     if not samesie:\n",
    "#         tempdict[FluxVar.instances[i].database.name] = FluxVar.instances[i]\n",
    "#         tempdict['id'] = FluxVar.instances[i].id\n",
    "#         tempdict['ra'] = FluxVar.instances[i].ra\n",
    "#         tempdict['dec'] = FluxVar.instances[i].dec\n",
    "#         tempdict['fk5'] = FluxVar.instances[i].fk5\n",
    "#         samesieslist.append(tempdict)\n",
    "\n",
    "\n",
    "# print \"\\\\begin{longtable}{c|c|c|c|c|c|c|c|c|c|c|c|c} \\n\\\n",
    "# \\\\toprule \\nFlux147.5MHz (Jy) & Tgss (Jy) & Flux74MHz (Jy)& Vlssr (Jy) & fk5 & Ra (deg) & Dec (deg) &tggsRa&tgssDec&\\\n",
    "# vlssrRa&vlssrDec& Id/Link & (y/n)  \\\\\\\\\\\\midrule \\n\\\\endfirsthead \\n\\\\toprule \\\n",
    "# \\nFlux147.5MHz (Jy) & Tgss (Jy) & Flux74MHz (Jy)& Vlssr (Jy)& fk5 & Ra (deg) & Dec (deg)  &tggsRa&tgssDec&\\\n",
    "# vlssrRa&vlssrDec& Id/Link & (y/n) \\\\\\\\\\\\midrule \\n\\\\endhead \\n\\\\bottomrule \\n\\\\endfoot \\n\\\\bottomrule\"\n",
    "\n",
    "# # define caption for table\n",
    "# print \"\\\\caption{ Comparison of variable fluxes with the same position for different databases 1hr} \\n\\\\endlastfoot\"\n",
    "# lastname = None\n",
    "# # samesieslist = sorted(samesieslist, key=lambda e: (e['ra'], e['dec']))\n",
    "# for i in samesieslist:\n",
    "#     a= ''\n",
    "#     b=''\n",
    "#     for j in(databaselist):\n",
    "#         try: \n",
    "#             a+= str(np.around(i[j].pflux*i[j].scale,3)) + \" \" + \"&\"+ \" \"\n",
    "#         except:\n",
    "#             a += \"-\" +\" \"+ \"&\"+ \" \"\n",
    "#         try:\n",
    "#             a+= str(np.around(i[j].database.pflux[i[j].entry],3)) + \" \" + \"&\"+ \" \"   \n",
    "#         except:\n",
    "#             a += \"-\" +\" \"+ \"&\"+ \" \"\n",
    "            \n",
    "#         try: \n",
    "#             b+= '%0.3f' %(i[j].database.ra[i[j].entry])+\" \"+\"&\"+\" \"\n",
    "#             b+= '%0.3f' %(i[j].database.dec[i[j].entry])+\" \"+\"&\"+\" \"\n",
    "#         except:\n",
    "#             b+= \"-\" + \" \" + \"&\"+\" \" \"-\" + \" \" + \"&\"+\" \"\n",
    "        \n",
    "#     a +=i['fk5'] + \" \" + '&' + \"  \"+ '%0.3f' %i['ra'] + \" \" + \"&\"+ \" \"+ \"%0.3f\" %i['dec'] \\\n",
    "#     + \" \" + '&' + \"  \"+ b+ latexHREF +str(i[\"id\"])+\"}\" + \"{%i}\" %i['id'] +\" \"+\"&\"+\" \"+  \"\\\\\" + \"\\\\\"\n",
    "#     print a\n",
    "\n",
    "# print \"\\\\end{longtable}\\n\"\n",
    "# print \"\\\\end{landscape}\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the Position variating sources in Latex ready format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SEPERATE DATABASES\n",
    "\n",
    "# print \"\\\\begin{longtable}{c|c|c|c|c|c} \\n\\\n",
    "# \\\\toprule \\nDatabase & Ra (deg) & Dec (deg) & Fk5 & Id/Link & Candidate? (y/n)  \\\\\\\\\\\\midrule \\n\\\\endfirsthead \\n\\\\toprule \\\n",
    "# \\nDatabase & Ra (deg) & Dec (deg) & Fk5 & Id/Link & Candidate? (y/n)  \\\\\\\\\\\\midrule \\n\\\\endhead \\n\\\\bottomrule \\n\\\\endfoot \\n\\\\bottomrule\"\n",
    "\n",
    "# # define caption for table\n",
    "# print \"\\\\caption{ Comparison position of candidates with different databases for the 10 min interval data} \\n\\\\endlastfoot\"\n",
    "# lastname = None\n",
    "# for i in PosVar.instances:\n",
    "#     if i.database.name != lastname and lastname:\n",
    "#         print \"\\\\hline\"\n",
    "#     print i.database.name +\" \"+ \"&\"+ \" \" + '%0.3f' %i.ra + \" \" + \"&\"+ \" \"+ \"%0.3f\" %i.dec +\\\n",
    "#     \" \" + \"&\" + \" \" + i.fk5 +\" \" + '&' + \"  \"+ latexHREF +str(i.id)+\"}\" + \"{%i}\" %i.id +\" \" + '&' + \"  \"+\"\\\\\" + \"\\\\\"\n",
    "    \n",
    "#     lastname = i.database.name\n",
    "\n",
    "# print \"\\\\end{longtable}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # COMBINED DATABASES (SLOWER)\n",
    "# print \"\\\\begin{1andscape}\\n\"\n",
    "# print \"\\\\section{Position variating Sources}\\n\"\n",
    "# samesieslist = []\n",
    "# for i in range(len(PosVar.instances)):\n",
    "#     samesie = False\n",
    "    \n",
    "# #   create combined name if entry both in vlssr and tgss\n",
    "#     for j in range(len(samesieslist)):\n",
    "#         if PosVar.instances[i].id == samesieslist[j][0]:\n",
    "#             samesieslist[j][1] = samesieslist[j][1] + \" \\& \" + PosVar.instances[i].database.name\n",
    "#             samesie = True\n",
    "#     if not samesie:\n",
    "#         samesieslist.append([PosVar.instances[i].id,PosVar.instances[i].database.name,PosVar.instances[i]])\n",
    "    \n",
    "# samesieslist = sorted(samesieslist, key=itemgetter(1))\n",
    "\n",
    "# print \"\\\\begin{longtable}{c|c|c|c|c|c} \\n\\\n",
    "# \\\\toprule \\nDatabase & Ra (deg) & Dec (deg)& Fk5 & Id/Link & Candidate? (y/n)  \\\\\\\\\\\\midrule \\n\\\\endfirsthead \\n\\\\toprule \\\n",
    "# \\nDatabase & Ra (deg) & Dec (deg) & Fk5 &Id/Link & Candidate? (y/n)  \\\\\\\\\\\\midrule \\n\\\\endhead \\n\\\\bottomrule \\n\\\\endfoot \\n\\\\bottomrule\"\n",
    "\n",
    "# # define caption for table\n",
    "# print \"\\\\caption{ Comparison position of candidates with different databases for the 1hr interval data} \\n\\\\endlastfoot\"\n",
    "# lastname = None\n",
    "# for i in samesieslist:\n",
    "#     if i[1] != lastname and lastname:\n",
    "#         print \"\\\\hline\"\n",
    "#     print i[1] +\" \"+ \"&\"+ \" \"+ '%0.3f' %i[2].ra + \" \" + \"&\"+ \" \"+ \"%0.3f\" %(i[2].dec) +\\\n",
    "#     \" \" + \"&\" + \" \" +i[2].fk5 +\" \" + '&' + \"  \"+ latexHREF +str(i[0])+\"}\" + \"{%i}\" %i[0] +\" \" + '&' + \"  \"+\"\\\\\" + \"\\\\\"\n",
    "    \n",
    "#     lastname = i[1]\n",
    "\n",
    "# print \"\\\\end{longtable}\\n\"\n",
    "# print \"\\\\end{landscape}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonwriter.WriteFluxJson(FluxVar.instances)\n",
    "print FluxVar.instances[1].ra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!{sys.executable} -m scrapy runspider scrapper.py -o neat.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.remove('neat.json')\n",
    "except:\n",
    "    print 'allready removed'\n",
    "\n",
    "!{sys.executable} -m scrapy runspider scrapper.py -o neat.json\n",
    "\n",
    " \n",
    "dfFlux = ljs.Loadin('neat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print dfFlux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# models to try\n",
    "def starmodel(value,a,b,c):\n",
    "    return a*value**-b+c\n",
    "\n",
    "def starmodel2(value,*par):\n",
    "    return 10**(-np.log(value)*par[0] + par[1])\n",
    "\n",
    "def starmodel3(value,*par):\n",
    "    return 10**(-np.log(value*par[0])-np.exp(value)*par[1] + par[2])\n",
    "\n",
    "def ChiSq2(parm, xval, yval, dy): # the weighted least-squares\n",
    "    ymod = starmodel2(xval,*parm)\n",
    "    chisq = sum(pow((yval-ymod)/dy,2))\n",
    "    return chisq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# specid = dfFlux[dfFlux.id == i]\n",
    "# print specid\n",
    "# freq = np.array(specid.nu)\n",
    "# print freq.astype(float)\n",
    "# ids = int(i)\n",
    "# freq = np.array(specid.nu.astype(float))\n",
    "# flux = np.array(specid.s_nu.astype(float))\n",
    "# fluxerr = np.array(specid.e.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlibfunction(frame,freq,flux,fluxerr,colour):\n",
    "    \n",
    "    \n",
    "    #xstart, ystart, xend, yend [units are fraction of the image frame, from bottom left corner]\n",
    "    \n",
    "    plt.errorbar(freq,flux,yerr = fluxerr,color=colour,fmt = '.',ecolor='black') #Noisy data\n",
    "\n",
    "\n",
    "# get our own data\n",
    "def getSourceData2(frame,runcat_id,colour):\n",
    "    runcat = session.query(tkp.db.model.Runningcatalog).filter(tkp.db.model.Runningcatalog.id==runcat_id).one()\n",
    "    sources = runcat.extractedsources\n",
    "    \n",
    "    flux = []\n",
    "    fluxerr = []\n",
    "    freq = []\n",
    "    \n",
    "    for s in sources:\n",
    "        if s.extract_type == 0:\n",
    "            flux.append(s.f_int*10**3)\n",
    "            fluxerr.append(s.f_int_err*10**3)\n",
    "            freq.append(s.image.freq_eff/(1.*10**6))\n",
    "\n",
    "    matplotlibfunction(frame,freq,flux,fluxerr,colour)\n",
    "# #Residual plot\n",
    "# difference = Fofx(x,*p) - ydata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot function\n",
    "def bokehplotfunction(d,freq,flux,fluxerr,colour):\n",
    "    lower = []\n",
    "    upper = []\n",
    "    base =[]\n",
    "    for i in range(len(flux)):\n",
    "        lower.append(flux[i]-fluxerr[i])\n",
    "        upper.append(flux[i]+fluxerr[i])\n",
    "        base.append(freq[i])\n",
    "\n",
    "    d.scatter(freq,flux,color =colour)\n",
    "    source_error = ColumnDataSource(data=dict(base=base, lower=lower, upper=upper))\n",
    "\n",
    "    d.add_layout(\n",
    "        Whisker(source=source_error, base=\"base\", upper=\"upper\", lower=\"lower\")\n",
    "    )\n",
    "    return d\n",
    "\n",
    "# make a fit\n",
    "def fitexistingdata(freq,flux,fluxerr,ids,x):\n",
    "    a=0.001\n",
    "    b = 10\n",
    "    c = 100\n",
    "\n",
    "        \n",
    "    p01=[b,c]\n",
    "    fitfunction = starmodel2\n",
    "        \n",
    "    ml_cfpars, ml_cfcovar = op.curve_fit(fitfunction, freq, flux, p01, sigma=fluxerr)\n",
    "    err = np.sqrt(np.diag(ml_cfcovar))\n",
    "    confidence = np.diag(ml_cfcovar)\n",
    "    fit = fitfunction(x, *ml_cfpars)\n",
    "    dof = len(freq)-len(p01)\n",
    "    chisquare = ChiSq2(ml_cfpars,freq,flux,fluxerr)\n",
    "    return fit,chisquare,dof,ml_cfpars, ml_cfcovar\n",
    "\n",
    "# get our own data\n",
    "def getSourceData(d,runcat_id,colour):\n",
    "    runcat = session.query(tkp.db.model.Runningcatalog).filter(tkp.db.model.Runningcatalog.id==runcat_id).one()\n",
    "    sources = runcat.extractedsources\n",
    "    \n",
    "    flux = []\n",
    "    fluxerr = []\n",
    "    freq = []\n",
    "    \n",
    "    for s in sources:\n",
    "        if s.extract_type == 0:\n",
    "            flux.append(s.f_int*10**3)\n",
    "            fluxerr.append(s.f_int_err*10**3)\n",
    "            freq.append(s.image.freq_eff/(1.*10**6))\n",
    "\n",
    "    bokehplotfunction(d,freq,flux,fluxerr,colour)\n",
    "    return d,freq,flux,fluxerr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THE FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "storedfitvalueslist = []\n",
    "# initialize x\n",
    "x = np.arange(1e1, 1e4, 1)\n",
    "\n",
    "# loops through the data gathered sorting by id and plotting the fit\n",
    "\n",
    "for i in dfFlux.id.unique():\n",
    "    specid = dfFlux[dfFlux.id == i]\n",
    "    ids = int(i)\n",
    "    try:\n",
    "        freq = np.array(specid.nu.astype(float))\n",
    "        flux = np.array(specid.s_nu.astype(float))\n",
    "        fluxerr = np.array(specid.e.astype(float))\n",
    "    except:\n",
    "        print 'hoi'\n",
    "        freq = np.array([])\n",
    "        flux = np.array([])\n",
    "        fluxerr=np.array([])\n",
    "    \n",
    "#     Append catalogue data to the set:\n",
    "    for j in FluxVar.instances:\n",
    "        if j.id == ids:\n",
    "            freq = np.append(freq,j.database.freq)\n",
    "            flux = np.append(flux,j.database.pflux[j.entry]*10**3 )\n",
    "            fluxerr = np.append(fluxerr,j.database.pfluxe[j.entry]*10**3 )\n",
    "\n",
    "    print freq\n",
    "    \n",
    "    #Initialize figure\n",
    "    fig1 = plt.figure(1,figsize=(10,10))\n",
    "    fig1.suptitle(\"Plot of: \" + str(ids),fontsize=20)\n",
    "    \n",
    "    #add first frame\n",
    "    frame1=fig1.add_axes((.1,.3,.8,.6))\n",
    "    matplotlibfunction(frame1,freq,flux,fluxerr,\"blue\")\n",
    "    \n",
    "\n",
    "    \n",
    "    try:\n",
    "        fit,chisquare,dof,ml_cfpars, ml_cfcovar = fitexistingdata(freq,flux,fluxerr,ids,x)\n",
    "\n",
    "    except:\n",
    "        print \"for id: %i there is no good fit\" %ids\n",
    "        chisquare = 0\n",
    "        dof = 0\n",
    "        fit = None\n",
    "        ml_cfpars = None\n",
    "        print freq\n",
    "\n",
    "    \n",
    "    try:\n",
    "        print \"with a goodness of fit of: %0.3f and a dof of: %0.1f\" %(chisquare,dof)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    getSourceData2(frame1,int(ids),colour = 'red')\n",
    "    \n",
    "#   initialize normal frame\n",
    "    frame1.set_xscale('log')\n",
    "    frame1.set_yscale('log')\n",
    "    frame1.set_xticklabels([]) #Remove x-tic labels for the first frame\n",
    "    frame1.set_ylabel(\"Flux (mJy)\",fontsize = 13)\n",
    "    try:\n",
    "        plt.plot(x,fit,color='green')\n",
    "    except:\n",
    "        pass\n",
    "    plt.grid()\n",
    "    \n",
    "    #   initialize residual frame\n",
    "    try:\n",
    "        frame2=fig1.add_axes((.1,.1,.8,.2),sharex = frame1) \n",
    "        matplotlibfunction(frame2,freq,(flux-starmodel2(freq,*ml_cfpars))/flux,fluxerr/flux,'green')\n",
    "        plt.axhline(0.0, color='purple', linestyle='dotted', lw=2)\n",
    "        frame2.set_xscale('log')\n",
    "        frame2.set_xlabel('Frequency (MHz)',fontsize=13)\n",
    "        plt.grid()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if savefigs:\n",
    "        try:\n",
    "            homedir = os.getcwd()\n",
    "            newdir = homedir+\"/\" +timescale+\"_\"+ technique\n",
    "            os.mkdir(newdir)\n",
    "            os.chdir(newdir)\n",
    "            plt.savefig(timescale + str(ids) +\".png\" )\n",
    "            os.chdir(homedir)\n",
    "        except:\n",
    "            os.chdir(newdir)\n",
    "            plt.savefig(timescale + str(ids) +\".png\" )\n",
    "            os.chdir(homedir)\n",
    "    try:\n",
    "        storedfitvalueslist.append([ids,chisquare,dof])\n",
    "    except:\n",
    "        storedfitvalueslist.append([ids,0,0])\n",
    "    plt.show() \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print storedfitvalueslist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not add tgss or vlssr data to the fit for this singular source where shit hits the fan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weirdactingid = 7605\n",
    "for i in dfFlux.id.unique():\n",
    "    if i == str(weirdactingid):\n",
    "        specid = dfFlux[dfFlux.id == i]\n",
    "        ids = int(i)\n",
    "        freq = np.array(specid.nu.astype(float))\n",
    "        flux = np.array(specid.s_nu.astype(float))\n",
    "        fluxerr = np.array(specid.e.astype(float))\n",
    "        ids = int(i)\n",
    "        \n",
    "for i in range(len(storedfitvalueslist)):\n",
    "    if storedfitvalueslist[i][0]== weirdactingid:\n",
    "        print storedfitvalueslist[i]\n",
    "        del(storedfitvalueslist[i])\n",
    "        \n",
    "# Initialize figure\n",
    "fig1 = plt.figure(1,figsize=(10,10))\n",
    "fig1.suptitle(\"Plot of: \" + str(ids),fontsize=20)\n",
    "\n",
    "#add frame1\n",
    "frame1=fig1.add_axes((.1,.3,.8,.6))\n",
    "matplotlibfunction(frame1,freq,flux,fluxerr,\"blue\")\n",
    "\n",
    "\n",
    "# initialize x\n",
    "x = np.arange(1e1, 1e4, 1)\n",
    "try:\n",
    "    fit,chisquare,dof,ml_cfpars, ml_cfcovar = fitexistingdata(freq,flux,fluxerr,ids,x)\n",
    "\n",
    "except:\n",
    "    print \"for id: %i there is no good fit\" %ids\n",
    "    print freq\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "for j in FluxVar.instances:\n",
    "    if j.id == ids:\n",
    "\n",
    "        matplotlibfunction(frame1,j.database.freq,j.database.pflux[j.entry]*10**3,j.database.pfluxe[j.entry]*10**3,colour='blue')\n",
    "\n",
    "\n",
    "\n",
    "getSourceData2(frame1,int(ids),colour = 'red')\n",
    "\n",
    "# Initialize normal frame\n",
    "frame1.set_xscale('log')\n",
    "frame1.set_yscale('log')\n",
    "frame1.set_xticklabels([]) #Remove x-tic labels for the first frame\n",
    "frame1.set_ylabel(\"Flux (mJy)\",fontsize = 13)\n",
    "plt.plot(x,fit,color='green')\n",
    "plt.grid()\n",
    "\n",
    "# initialize residuals frame\n",
    "frame2=fig1.add_axes((.1,.1,.8,.2),sharex = frame1) \n",
    "matplotlibfunction(frame2,freq,(flux-starmodel2(freq,*ml_cfpars))/flux,fluxerr/flux,'green')\n",
    "plt.axhline(0.0, color='purple', linestyle='dotted', lw=2)\n",
    "frame2.set_xscale('log')\n",
    "frame2.set_xlabel('Frequency (MHz)',fontsize=13)\n",
    "plt.grid()\n",
    "\n",
    "storedfitvalueslist.append([ids,chisquare,dof])\n",
    "# if we wanna save we save\n",
    "if savefigs:\n",
    "    os.chdir(newdir)\n",
    "    plt.savefig(timescale + str(ids) +\".png\" )\n",
    "    os.chdir(homedir)\n",
    "plt.show()\n",
    "# make figure for and get the residuals\n",
    "\n",
    "# p = figure(title=\"residuals\", x_axis_label='freq (MHz)', y_axis_label='flux(mJy)',x_axis_type='log')\n",
    "\n",
    "\n",
    "# p = bokehplotfunction(p,freq,(flux-starmodel2(freq,*ml_cfpars))/flux,fluxerr/flux,'green')\n",
    "# p.line(x,0,color='purple',line_dash='dashed')\n",
    "\n",
    "# show(p)\n",
    "print \"__________________________________________________________________________________________\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Reg.file for quick comparison in original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir(newdir)\n",
    "except:\n",
    "    homedir = os.getcwd()\n",
    "    newdir = homedir+\"/\" +timescale+ \"_\"+technique\n",
    "    os.mkdir(newdir)\n",
    "    os.chdir(newdir)\n",
    "\n",
    "wr.WriteReg(timescale,PosVar.instances,FluxVar.instances)\n",
    "os.chdir(homedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST MAKE IMAGES FOR TGSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonwriter.WriteFluxJson(FluxVar.instances,pos=True)\n",
    "jsonFile = open(\"tgpos.json\",\"r\")\n",
    "datalistjson = json.load(jsonFile)\n",
    "n = len(datalistjson)\n",
    "jsonFile.close()\n",
    "try:\n",
    "    os.remove('poslink.json')\n",
    "except:\n",
    "    print 'allready removed'\n",
    "for i in range(n):\n",
    "    !{sys.executable} -m scrapy runspider databasescrapper.py -o poslink.json\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download tgss fits images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# os.chdir(homedir)\n",
    "# try:\n",
    "#     os.rename(homedir+\"/poslink.json\", newdir+\"/poslink.json\")\n",
    "# except:\n",
    "#     pass\n",
    "# try:\n",
    "#     os.rename(homedir+\"/downloader.py\", newdir+\"/downloader.py\")\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "\n",
    "# os.chdir(newdir)\n",
    "# !{sys.executable} downloader.py\n",
    "\n",
    "# try:\n",
    "#     os.rename(newdir+\"/downloader.py\", homedir+\"/downloader.py\")\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# os.chdir(homedir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert fits to png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# os.chdir(newdir)\n",
    "# imagez = glob.glob('*.fits')\n",
    "# # for i in imagez:\n",
    "# # #     print i\n",
    "# #     rpf.Imager(i)\n",
    "# for i in PosVar.instances:\n",
    "#     if i.dataname == 'tgss':\n",
    "#         a = str(i.id) +'tgss.fits'\n",
    "#         print i.ra\n",
    "#         print i.dec\n",
    "#         print i.id\n",
    "#         rpf.Imager(a,i.ra,i.dec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make cutouts vlssr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(homedir)\n",
    "os.chdir(newdir)\n",
    "\n",
    "for i in PosVar.instances:\n",
    "    if i.dataname == 'vlssr':\n",
    "        ct.GetCutout('../vlssrimage.fits',i.ra,i.dec,i.id,'vlssr')\n",
    "#         ct.GetCutout('../vlssrimage.fits',i.ra,i.dec,i.id,(120,120),'vlssr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make cutouts tgss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(homedir)\n",
    "# os.rename('tgssimage.fits','/'+newdir+\"tgssimage.fits\")\n",
    "os.chdir(newdir)\n",
    "\n",
    "for i in PosVar.instances:\n",
    "    if i.dataname == 'tgss':\n",
    "        ct.GetCutout('../tgssimage.fits',i.ra,i.dec,i.id,'tgss')\n",
    "#         ct.GetCutout('../tgssimage.fits',i.ra,i.dec,i.id,(120,120),'tgss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##VLSSR\n",
    "\n",
    "WCS Keywords\n",
    "\n",
    "Number of WCS axes: 2\n",
    "CTYPE : 'RA---SIN'  'DEC--SIN'  \n",
    "CRVAL : 180.0  45.0  \n",
    "CRPIX : 2040.0  2040.0  \n",
    "PC1_1 PC1_2  : 1.0  0.0  \n",
    "PC2_1 PC2_2  : 0.0  1.0  \n",
    "CDELT : -0.004166667  0.004166667  \n",
    "NAXIS : 0  0\n",
    "[120. 120.] pix\n",
    "WCS Keywords\n",
    "\n",
    "Number of WCS axes: 4\n",
    "CTYPE : 'RA---SIN'  'DEC--SIN'  'FREQ'  'STOKES'  \n",
    "CRVAL : 180.0  45.0  73793896.48435  1.0  \n",
    "CRPIX : 2040.0  2040.0  1.0  1.0  \n",
    "NAXIS : 4079  4079  1  1\n",
    "##TGSS\n",
    "WCS Keywords\n",
    "\n",
    "Number of WCS axes: 2\n",
    "CTYPE : 'RA---SIN'  'DEC--SIN'  \n",
    "CRVAL : 184.9973647014  46.77399545885  \n",
    "CRPIX : 2643.0  2807.0  \n",
    "CD1_1 CD1_2  : -0.001722222194076  0.0  \n",
    "CD2_1 CD2_2  : 0.0  0.001722222194076  \n",
    "NAXIS : 0  0\n",
    "[120. 120.] pix\n",
    "WCS Keywords\n",
    "\n",
    "Number of WCS axes: 2\n",
    "CTYPE : 'RA---TAN'  'DEC--TAN'  \n",
    "CRVAL : 184.9973647014  46.77399545885  \n",
    "CRPIX : 2643.0  2807.0  \n",
    "CD1_1 CD1_2  : -0.001722222194076  0.0  \n",
    "CD2_1 CD2_2  : 0.0  0.001722222194076  \n",
    "NAXIS : 5285  5613\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check weird source!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in FluxVar.instances:\n",
    "    if i.id == 3743:\n",
    "        print i.id\n",
    "        ct.GetCutout('../vlssrimage.fits',i.ra,i.dec,i.id,'vlssr')\n",
    "        ct.GetCutout('../tgssimage.fits',i.ra,i.dec,i.id,'tgss')\n",
    "        url = '/scratch/kmeulen/SourceSubstractedP23HetdexDir/Images/August/10min/10min_allband-t0018-image-pb.fits'\n",
    "        ct.GetCutout(url,i.ra,i.dec,i.id)\n",
    "    if i.id == 4320:\n",
    "        print i.id\n",
    "        ct.GetCutout('../vlssrimage.fits',i.ra,i.dec,i.id,'vlssr')\n",
    "        ct.GetCutout('../tgssimage.fits',i.ra,i.dec,i.id,'tgss')\n",
    "        print i.ra\n",
    "        print i.dec\n",
    "        url = '/scratch/kmeulen/SourceSubstractedP23HetdexDir/Images/August/10min/10min_allband-t0029-image-pb.fits'\n",
    "#         print i.ra\n",
    "#         print i.dec\n",
    "#         url = '/scratch/kmeulen/SourceSubstractedP23HetdexDir/Images/August/1hr/1hr_allband-t0003-image-pb.fits'\n",
    "        \n",
    "        ct.GetCutout(i.url[0],i.ra,i.dec,i.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make cutouts of own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(homedir)\n",
    "os.chdir(newdir)\n",
    "for i in PosVar.instances:\n",
    "        if i.id == 4977:\n",
    "            url = '/scratch/kmeulen/SourceSubstractedP23HetdexDir/Images/August/10min/10min_allband-t0040-image-pb.fits'\n",
    "            ct.GetCutout(url,i.ra,i.dec,i.id)\n",
    "        elif i.id == 4209:\n",
    "            url = '/scratch/kmeulen/SourceSubstractedP23HetdexDir/Images/August/10min/10min_allband-t0025-image-pb.fits'\n",
    "            \n",
    "            ct.GetCutout(url,i.ra,i.dec,i.id)\n",
    "        \n",
    "        else:\n",
    "            print i.url\n",
    "            print i.id\n",
    "            ct.GetCutout(i.url[0],i.ra,i.dec,i.id)\n",
    "\n",
    "# 1min_allband_2048_8asec-t0193-image-pb.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot in Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print \"\\\\begin{longtable}{m{1cm}|m{6cm}|m{6cm}|m{6cm}} \\n\\\n",
    "# \\\\toprule \\nId & Data & TGSS (deg)& VLSSR  \\\\\\\\\\\\midrule \\n\\\\endfirsthead \\n\\\\toprule \\\n",
    "# \\nId & Data & TGSS (deg)& VLSSR   \\\\\\\\\\\\midrule \\n\\\\endhead \\n\\\\bottomrule \\n\\\\endfoot \\n\\\\bottomrule\"\n",
    "\n",
    "# # define caption for table\n",
    "# print \"\\\\caption{ Comparison position of candidates with different databases for the 1hr interval data} \\n\\\\endlastfoot\"\n",
    "\n",
    "# for i in samesieslist:\n",
    "#     a = \"\\\\raisebox{-\\\\totalheight}{\\\\includegraphics[width=6cm, height=6cm]{\"+technique+\"/\"+str(i[0])+\"cutout_own.png}}\"+\" & \"\n",
    "#     if i[1] == \"tgss\":\n",
    "#         b = (\"\\\\raisebox{-\\\\totalheight}{\\\\includegraphics[width=6cm, height=6cm]{\"+technique+\"/\"+str(i[0])+\"cutout_tgss.png}}\"+\" & - \\\\\\\\\")\n",
    "#     if i[1] ==\"vlssr\":\n",
    "#         b = (\"- & \\\\raisebox{-\\\\totalheight}{\\\\includegraphics[width=6cm, height=6cm]{\"+technique+\"/\"+str(i[0])+\"cutout_vlssr.png}} \\\\\\\\\")\n",
    "#     if i[1] == \"tgss \\\\& vlssr\":\n",
    "#         b = (\"\\\\raisebox{-\\\\totalheight}{\\\\includegraphics[width=6cm, height=6cm]{\"+technique+\"/\"+str(i[0])+\"cutout_tgss.png}}\"+\" \"+ \"&\"\\\n",
    "#                 + \" \"+ \"\\\\raisebox{-\\\\totalheight}{\\\\includegraphics[width=6cm, height=6cm]{\"+technique+\"/\"+str(i[0])+\"cutout_vlssr.png}} \\\\\\\\\")\n",
    "#     print latexHREF +str(i[0])+\"}\" + \"{%i}\" %i[0]+\" \"+ \"&\"+ \" \"+ a + b\n",
    "\n",
    "# print \"\\\\end{longtable}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PRINT EVERYTHING IN LATEX IN ONE GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "folder = technique+\"_\"+timescale+\"/\"\n",
    "##############################\n",
    "# HERE WE PRINT THE NECESSARY PACKAGES\n",
    "##############################\n",
    "print\"\"\"\n",
    "\\documentclass{article}\n",
    "\\usepackage[utf8]{inputenc}\n",
    "\\usepackage[utf8]{inputenc}\n",
    "\\usepackage{geometry}\n",
    "\\usepackage{booktabs}\n",
    "\\usepackage{array}\n",
    "\\usepackage{graphicx}% delete the demo option in your actual code\n",
    "\\usepackage{longtable}\n",
    "\\usepackage{pdflscape}\n",
    "\\usepackage{mathabx}\n",
    "\\usepackage{float}\n",
    "\\usepackage{multirow}\n",
    "\\usepackage{multicol}\n",
    "\\usepackage{bigstrut}\n",
    "\\usepackage{caption}\n",
    "\\usepackage{subcaption}\n",
    "\\usepackage{siunitx}\n",
    "\\usepackage{makecell}\n",
    "\\usepackage{textcomp}\n",
    "\\usepackage{titlesec}\n",
    "\\usepackage[para]{footmisc}\n",
    "\\usepackage[nottoc]{tocbibind}\n",
    "\\usepackage{hyperref}\n",
    "\\geometry{lmargin=.5cm,bmargin=0.5cm,rmargin=1.5cm}\n",
    "\\hypersetup{\n",
    "    colorlinks=true,\n",
    "    linkcolor=blue,\n",
    "    filecolor=magenta,      \n",
    "    urlcolor=cyan,\n",
    "}\n",
    "\\\\begin{document}\n",
    "\"\"\"\n",
    "##########################\n",
    "# HERE WE PRINT THE NUMBER TABLES OF POSITION VARIATING SOURCES\n",
    "###########################\n",
    "print \"\\\\section{Position variating Sources}\\\\label{possection:\"+technique+\":\"+timescale+\"}\\n\"\n",
    "samesieslist = []\n",
    "for i in range(len(PosVar.instances)):\n",
    "    samesie = False\n",
    "    \n",
    "#   create combined name if entry both in vlssr and tgss\n",
    "    for j in range(len(samesieslist)):\n",
    "        if PosVar.instances[i].id == samesieslist[j][0]:\n",
    "            samesieslist[j][1] = samesieslist[j][1] + \" \\& \" + PosVar.instances[i].database.name\n",
    "            samesie = True\n",
    "    if not samesie:\n",
    "        samesieslist.append([PosVar.instances[i].id,PosVar.instances[i].database.name,PosVar.instances[i]])\n",
    "    \n",
    "samesieslist = sorted(samesieslist, key=itemgetter(1))\n",
    "\n",
    "print \"\\\\begin{longtable}{c|c|c|c|c} \\n\\\n",
    "\\\\toprule \\nDatabase & Ra (deg) & Dec (deg)& Fk5 & Id/Link \\\\\\\\\\\\midrule \\n\\\\endfirsthead \\n\\\\toprule \\\n",
    "\\nDatabase & Ra (deg) & Dec (deg) & Fk5 &Id/Link  \\\\\\\\\\\\midrule \\n\\\\endhead \\n\\\\bottomrule \\n\\\\endfoot \\n\\\\bottomrule\"\n",
    "\n",
    "# define caption for table\n",
    "print \"\\\\caption{ Comparison position of candidates with TGSS and VLSSR for the \" +timescale+\" timescale data} \\n\\\\endlastfoot\\n\\\n",
    "\\\\label{\"+technique+\":\"+timescale+\":tablepos\"+\"}\\n\"\n",
    "\n",
    "lastname = None\n",
    "for i in samesieslist:\n",
    "    if i[1] != lastname and lastname:\n",
    "        print \"\\\\hline\"\n",
    "    print i[1] +\" \"+ \"&\"+ \" \"+ '%0.3f' %i[2].ra + \" \" + \"&\"+ \" \"+ \"%0.3f\" %(i[2].dec) +\\\n",
    "    \" \" + \"&\" + \" \" +i[2].fk5 +\" \" + '&' + \"  \"+ latexHREF +str(i[0])+\"}\" + \"{%i}\" %i[0] +\" \\\\\" + \"\\\\\"\n",
    "    \n",
    "    lastname = i[1]\n",
    "\n",
    "print \"\\\\end{longtable}\\n\"\n",
    "\n",
    "\n",
    "#########################\n",
    "# HERE WE PRINT HE FIGURE TABLES\n",
    "#####################\n",
    "print \"\\\\subsection{Images}\"\n",
    "\n",
    "print \"\\\\begin{longtable}{m{1cm}|m{6cm}|m{6cm}|m{6cm}} \\n\\\n",
    "\\\\toprule \\nId & Data & TGSS (deg)& VLSSR  \\\\\\\\\\\\midrule \\n\\\\endfirsthead \\n\\\\toprule \\\n",
    "\\nId & Data & TGSS (deg)& VLSSR   \\\\\\\\\\\\midrule \\n\\\\endhead \\n\\\\bottomrule \\n\\\\endfoot \\n\\\\bottomrule\"\n",
    "\n",
    "# define caption for table\n",
    "print \"\\\\caption{Images to compare the  position of our candidates with TGSS and VLSSR for the \" +timescale+\" timescale data} \\n\\\\endlastfoot\"\n",
    "print \"\\\\label{\"+technique+\":\"+timescale+\":tablepos_images\"+\"}\"\n",
    "for i in samesieslist:\n",
    "    a = \"\\\\raisebox{-\\\\totalheight}{\\\\includegraphics[width=6cm, height=6cm]{\"+folder+str(i[0])+\"cutout_own.png}}\"+\" & \"\n",
    "    if i[1] == \"tgss\":\n",
    "        b = (\"\\\\raisebox{-\\\\totalheight}{\\\\includegraphics[width=6cm, height=6cm]{\"+folder+str(i[0])+\"cutout_tgss.png}}\"+\" & - \\\\\\\\\")\n",
    "    if i[1] ==\"vlssr\":\n",
    "        b = (\"- & \\\\raisebox{-\\\\totalheight}{\\\\includegraphics[width=6cm, height=6cm]{\"+folder+str(i[0])+\"cutout_vlssr.png}} \\\\\\\\\")\n",
    "    if i[1] == \"tgss \\\\& vlssr\":\n",
    "        b = (\"\\\\raisebox{-\\\\totalheight}{\\\\includegraphics[width=6cm, height=6cm]{\"+folder+str(i[0])+\"cutout_tgss.png}}\"+\" \"+ \"&\"\\\n",
    "                + \" \"+ \"\\\\raisebox{-\\\\totalheight}{\\\\includegraphics[width=6cm, height=6cm]{\"+folder+str(i[0])+\"cutout_vlssr.png}} \\\\\\\\\")\n",
    "    print latexHREF +str(i[0])+\"}\" + \"{%i}\" %i[0]+\" \"+ \"&\"+ \" \"+ a + b\n",
    "\n",
    "print \"\\\\end{longtable}\\n\"\n",
    "\n",
    "##########################\n",
    "# HERE WE PRINT THE NUMBER TABLES OF FLUX VARIATING SOURCES\n",
    "###########################\n",
    "\n",
    "print \"\\\\begin{landscape}\\n\"\n",
    "print \"\\\\section{Fluxvariating Sources}\\\\label{varsection:\"+technique+\":\"+timescale+\"}\\n\"\n",
    "# SEPERATE DATABASES\n",
    "databaselist = ['tgss','vlssr']\n",
    "\n",
    "samesieslist = []\n",
    "for i in range(len(FluxVar.instances)):\n",
    "    samesie = False\n",
    "    tempdict = {'tgss':None,'vlssr':None,'id':None,'ra':None,'dec':None,'fk5':None}\n",
    "    \n",
    "#   create combined name if entry both in vlssr and tgss\n",
    "    for j in range(len(samesieslist)):\n",
    "        if FluxVar.instances[i].id == samesieslist[j]['id']:\n",
    "#             samesieslist[j].append(FluxVar.instances[i])\n",
    "            samesieslist[j][FluxVar.instances[i].database.name] = FluxVar.instances[i]\n",
    "          \n",
    "            samesie = True\n",
    "    if not samesie:\n",
    "        tempdict[FluxVar.instances[i].database.name] = FluxVar.instances[i]\n",
    "        tempdict['id'] = FluxVar.instances[i].id\n",
    "        tempdict['ra'] = FluxVar.instances[i].ra\n",
    "        tempdict['dec'] = FluxVar.instances[i].dec\n",
    "        tempdict['fk5'] = FluxVar.instances[i].fk5\n",
    "        samesieslist.append(tempdict)\n",
    "\n",
    "\n",
    "print \"\\\\begin{longtable}{c|c|c|c|c|c|c|c|c|c|c|c} \\n\\\n",
    "\\\\toprule \\nFlux147.5MHz (Jy) & Tgss (Jy) & Flux74MHz (Jy)& Vlssr (Jy) & fk5 & Ra (deg) & Dec (deg) &tggsRa&tgssDec&\\\n",
    "vlssrRa&vlssrDec& Id/Link \\\\\\\\\\\\midrule \\n\\\\endfirsthead \\n\\\\toprule \\\n",
    "\\nFlux147.5MHz (Jy) & Tgss (Jy) & Flux74MHz (Jy)& Vlssr (Jy)& fk5 & Ra (deg) & Dec (deg)  &tggsRa&tgssDec&\\\n",
    "vlssrRa&vlssrDec& Id/Link \\\\\\\\\\\\midrule \\n\\\\endhead \\n\\\\bottomrule \\n\\\\endfoot \\n\\\\bottomrule\"\n",
    "\n",
    "# define caption for table\n",
    "print \"\\\\caption{ Comparison of fluxes that vary from catalogues TGSS and VLSSR for \" + timescale+\" images\"+\"} \\n\\\\endlastfoot\"\n",
    "print \"\\\\label{\"+technique+\":\"+timescale+\":tablevar\"+\"}\"\n",
    "lastname = None\n",
    "# samesieslist = sorted(samesieslist, key=lambda e: (e['ra'], e['dec']))\n",
    "for i in samesieslist:\n",
    "    a= ''\n",
    "    b=''\n",
    "    for j in(databaselist):\n",
    "        try: \n",
    "            a+= str(np.around(i[j].pflux*i[j].scale,3)) + \" \" + \"&\"+ \" \"\n",
    "        except:\n",
    "            a += \"-\" +\" \"+ \"&\"+ \" \"\n",
    "        try:\n",
    "            a+= str(np.around(i[j].database.pflux[i[j].entry],3)) + \" \" + \"&\"+ \" \"   \n",
    "        except:\n",
    "            a += \"-\" +\" \"+ \"&\"+ \" \"\n",
    "            \n",
    "        try: \n",
    "            b+= '%0.3f' %(i[j].database.ra[i[j].entry])+\" \"+\"&\"+\" \"\n",
    "            b+= '%0.3f' %(i[j].database.dec[i[j].entry])+\" \"+\"&\"+\" \"\n",
    "        except:\n",
    "            b+= \"-\" + \" \" + \"&\"+\" \" \"-\" + \" \" + \"&\"+\" \"\n",
    "        \n",
    "    a +=i['fk5'] + \" \" + '&' + \"  \"+ '%0.3f' %i['ra'] + \" \" + \"&\"+ \" \"+ \"%0.3f\" %i['dec'] \\\n",
    "    + \" \" + '&' + \"  \"+ b+ latexHREF +str(i[\"id\"])+\"}\" + \"{%i}\" %i['id'] +\"  \\\\\" + \"\\\\\"\n",
    "    print a\n",
    "\n",
    "print \"\\\\end{longtable}\\n\"\n",
    "print \"\\\\end{landscape}\\n\"\n",
    "\n",
    "################\n",
    "## HERE ARE THE PLOTS:\n",
    "################\n",
    "print \"\\\\subsection{Fits}\"\n",
    "\n",
    "i = 0\n",
    "try:\n",
    "    while i < len(storedfitvalueslist):\n",
    "        print \"\\\n",
    "\\\\begin{figure}[H]\\n\\\n",
    "    \\\\centering\\n\\\n",
    "    \\\\begin{minipage}{.5\\\\textwidth}\\n\\\n",
    "        \\\\centering\\n\\\n",
    "        \\\\includegraphics[scale = 0.35]{\"+folder+timescale+str(storedfitvalueslist[i][0])+\".png}\\n\\\n",
    "        \\\\captionsetup{labelformat=empty}\\n\\\n",
    "        \\\\caption{Plot of source: \"+latexHREF +str(storedfitvalueslist[i][0])+\"}\"+\"{%i}\" %storedfitvalueslist[i][0]\\\n",
    "    +\",\\\\\\\\with a goodness of fit of: %0.2f and a dof of: %i\"\\\n",
    "    %(storedfitvalueslist[i][1],storedfitvalueslist[i][2]) +\"}\\n\\\n",
    "        \\\\addtocounter{figure}{-1}\\n\\\n",
    "        \\\\label{\"+technique+\":\"+timescale+\":\"+str(storedfitvalueslist[i][0]) +\":plot}\\n\\\n",
    "    \\\\end{minipage}%\\n\\\n",
    "    \\\\begin{minipage}{0.5\\\\textwidth}\\n\\\n",
    "        \\\\centering\\n\"\n",
    "        try:\n",
    "            print\"\\\n",
    "        \\\\includegraphics[scale = 0.35]{\"+folder+timescale+str(storedfitvalueslist[i+1][0])+\".png}\\n\\\n",
    "        \\\\captionsetup{labelformat=empty}\\n\\\n",
    "        \\\\caption{Plot of source: \"+latexHREF +str(storedfitvalueslist[i+1][0])+\"}\"+\"{%i}\" %storedfitvalueslist[i+1][0]\\\n",
    "    +\",\\\\\\\\with a goodness of fit of: \"+str(storedfitvalueslist[i+1][1].round(2))+\\\n",
    "    \" and a dof of: \"+str(storedfitvalueslist[i+1][2])+\"\"\\\n",
    "    +\"}\\n\\\n",
    "    \\\\addtocounter{figure}{-1}\\n\\\n",
    "    \\\\label{\"+technique+\":\"+timescale+\":\"+str(storedfitvalueslist[i+1][0]) +\":plot}\\n\\\n",
    "    \\\\end{minipage}\\n\\\n",
    "\\\\end{figure}\"\n",
    "        except:\n",
    "            print \"--\\n\\\n",
    "        \\\\end{minipage}\\n\\\n",
    "\\\\end{figure}\"\n",
    "        if (i+2)%8==0 and i !=0:\n",
    "            if i+2 ==8:\n",
    "                pass\n",
    "            else:\n",
    "                print \"\\\\newpage\"\n",
    "        i+=2\n",
    "except:\n",
    "    pass\n",
    "########    \n",
    "#JUST FOR ME:\n",
    "#######\n",
    "print \"\\\\section{Effect on Candidate List}\"\n",
    "print \"\\\n",
    "\\\\begin{table}[H]\\n\\\n",
    "    \\\\centering\\n\\\n",
    "    \\\\begin{tabular}{|c| c | c|}\\n\\\n",
    "    \\\\toprule\\n\\\n",
    "     Step & Candidate list before & Candidate list after\\\\\\\\\\n\\\n",
    "    \\\\midrule\\n\\\n",
    "        Initial Selector & \"+str(initiallenghtcandi)+\" & \" + str(initialselector) +\" \\\\\\\\\\n\\\n",
    "        PosVarCandi & \"+str(initialselector)+\" & \" + str(posvarcatasave) +\" \\\\\\\\\\n\\\n",
    "        FluxVarCandi & \"+str(initialselector)+\" & \" + str(fluxvarcatasave) +\"  \\\\\\\\\\n\\\n",
    "        \\\\midrule\\n\\\n",
    "    \\\\end{tabular}\\n\\\n",
    "    \\\\caption{Effect of our script on the size of the candidate list for the \"+timescale+\" timescale images}\\n\\\n",
    "    \\\\label{\"+technique+\":\"+timescale+\":\"+\"overviewcandidates}\\n\\\n",
    "\\\\end{table}\\n\"\n",
    "\n",
    "###############    \n",
    "# ENDING THE DOCUMENT\n",
    "##############\n",
    "print \"\\\\end{document}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to <a href=#bookmark>beginning</a>\n",
    "Left off here <a name='bookmark2' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# i = 0\n",
    "# while i < len(storedfitvalueslist):\n",
    "#     print \"\\\n",
    "# \\\\begin{figure}[H]\\n\\\n",
    "#     \\\\centering\\n\\\n",
    "#     \\\\begin{minipage}{.5\\\\textwidth}\\n\\\n",
    "#         \\\\centering\\n\\\n",
    "#         \\\\includegraphics[scale = 0.35]{\"+technique+\"/\"+timescale+str(storedfitvalueslist[i][0])+\".png}\\n\\\n",
    "#         \\\\captionsetup{labelformat=empty}\\n\\\n",
    "#         \\\\caption{\\\\textbf{a:} Plot of \"+latexHREF +str(storedfitvalueslist[i][0])+\"}\"+\"{%i}\" %storedfitvalueslist[i][0]\\\n",
    "#     +\",\\\\\\\\with a goodness of fit of: %0.2f and a dof of: %i\"\\\n",
    "#     %(storedfitvalueslist[i][1],storedfitvalueslist[i][2]) +\"}\\n\\\n",
    "#         \\\\addtocounter{figure}{-1}\\n\\\n",
    "#         \\\\label{\"+technique+\":\"+timescale+\":\"+str(storedfitvalueslist[i][0]) +\":plot}\\n\\\n",
    "#     \\\\end{minipage}%\\n\\\n",
    "#     \\\\begin{minipage}{0.5\\\\textwidth}\\n\\\n",
    "#         \\\\centering\\n\\\n",
    "#         \\\\includegraphics[scale = 0.35]{\"+technique+\"/\"+timescale+str(storedfitvalueslist[i][0])+\".png}\\n\\\n",
    "#         \\\\captionsetup{labelformat=empty}\\n\\\n",
    "#         \\\\caption{\\\\textbf{b:} Plot of \"+latexHREF +str(storedfitvalueslist[i+1][0])+\"}\"+\"{%i}\" %storedfitvalueslist[i+1][0]\\\n",
    "#     +\",\\\\\\\\with a goodness of fit of: \"+str(storedfitvalueslist[i+1][1].round(2))+\\\n",
    "#     \" and a dof of: \"+str(storedfitvalueslist[i+1][2])+\"\"\\\n",
    "#     +\"}\\n\\\n",
    "#     \\\\addtocounter{figure}{-1}\\n\\\n",
    "#     \\\\label{\"+technique+\":\"+timescale+\":\"+str(storedfitvalueslist[i+1][0]) +\":plot}\\n\\\n",
    "#     \\\\end{minipage}\\n\\\n",
    "# \\\\end{figure}\"\n",
    "#     if (i+2)%8==0 and i !=0:\n",
    "#         if i+2 ==8:\n",
    "#             pass\n",
    "#         else:\n",
    "#             print \"\\\\newpage\"\n",
    "#     i+=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In case no sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print\"\"\"\n",
    "\\documentclass{article}\n",
    "\\usepackage[utf8]{inputenc}\n",
    "\\usepackage[utf8]{inputenc}\n",
    "\\usepackage{geometry}\n",
    "\\usepackage{booktabs}\n",
    "\\usepackage{array}\n",
    "\\usepackage{graphicx}% delete the demo option in your actual code\n",
    "\\usepackage{longtable}\n",
    "\\usepackage{pdflscape}\n",
    "\\usepackage{mathabx}\n",
    "\\usepackage{float}\n",
    "\\usepackage{multirow}\n",
    "\\usepackage{multicol}\n",
    "\\usepackage{bigstrut}\n",
    "\\usepackage{caption}\n",
    "\\usepackage{subcaption}\n",
    "\\usepackage{siunitx}\n",
    "\\usepackage{makecell}\n",
    "\\usepackage{textcomp}\n",
    "\\usepackage{titlesec}\n",
    "\\usepackage[para]{footmisc}\n",
    "\\usepackage[nottoc]{tocbibind}\n",
    "\\usepackage{hyperref}\n",
    "\\geometry{lmargin=.5cm,bmargin=0.5cm,rmargin=1.5cm}\n",
    "\\hypersetup{\n",
    "    colorlinks=true,\n",
    "    linkcolor=blue,\n",
    "    filecolor=magenta,      \n",
    "    urlcolor=cyan,\n",
    "}\n",
    "\\\\begin{document}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print \"\\\\section{Effect on Candidate List}\"\n",
    "print \"\\\n",
    "\\\\begin{table}[H]\\n\\\n",
    "    \\\\centering\\n\\\n",
    "    \\\\begin{tabular}{|c| c | c|}\\n\\\n",
    "    \\\\toprule\\n\\\n",
    "     Step & Candidate list before & Candidate list after\\\\\\\\\\n\\\n",
    "    \\\\midrule\\n\\\n",
    "        Initial Selector & \"+str(0)+\" & \" + str(0) +\" \\\\\\\\\\n\\\n",
    "        PosVarCandi & \"+str(0)+\" & \" + str(0) +\" \\\\\\\\\\n\\\n",
    "        FluxVarCandi & \"+str(0)+\" & \" + str(0) +\"  \\\\\\\\\\n\\\n",
    "        \\\\midrule\\n\\\n",
    "    \\\\end{tabular}\\n\\\n",
    "    \\\\caption{Effect of our script on the size of the candidate list for the \"+timescale+\" timescale images}\\n\\\n",
    "    \\\\label{\"+technique+\":\"+timescale+\":\"+\"overviewcandidates}\\n\\\n",
    "\\\\end{table}\\n\"\n",
    "\n",
    "\n",
    "print \"\\\\end{document}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
