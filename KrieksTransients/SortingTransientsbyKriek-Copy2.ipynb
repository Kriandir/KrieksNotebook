{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import io, os, sys, types\n",
    "\n",
    "# this import imports the databaseloader script (which only does TGSS and VLSSR for now)\n",
    "import Databaseloader as dl\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tkp.db\n",
    "from tkp.db.model import Varmetric\n",
    "from tkp.db.model import Runningcatalog\n",
    "from tkp.db.model import Newsource\n",
    "from tkp.db.model import Extractedsource\n",
    "from tkp.db.model import Image\n",
    "from operator import itemgetter, attrgetter\n",
    "import logging\n",
    "from pandas import DataFrame\n",
    "import sqlalchemy\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy.orm import relationship\n",
    "#import Tools\n",
    "#import generic_tools\n",
    "#import plotting_tools\n",
    "from scipy.stats import norm\n",
    "import pylab\n",
    "pylab.rcParams['legend.loc'] = 'best'\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.font_manager import FontProperties\n",
    "#from astroML import density_estimation\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy.spatial import distance\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = 'postgresql'\n",
    "host = 'vlo.science.uva.nl'\n",
    "port = 5432\n",
    "user = 'kmeulen'\n",
    "password = 'kLu2oepRouv2UfoUPhoU'\n",
    "database='KmeulenTrap4P23'\n",
    "websiteURL = 'http://banana.transientskp.org/r4/vlo_'+database+'/runningcatalog/'\n",
    "latexURL = '\\url{http://banana.transientskp.org/r4/vlo_'+database+'/runningcatalog/'\n",
    "query_loglevel = logging.WARNING  # Set to INFO to see queries, otherwise WARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tkp.db.database:Database config: postgresql://kmeulen@vlo.science.uva.nl:5432/KmeulenTrap4P23\n",
      "/home/kmeulen/virtualenv/local/lib/python2.7/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n",
      "INFO:tkp.db.database:connecting to database...\n",
      "INFO:tkp.db.database:connected to: postgresql://kmeulen@vlo.science.uva.nl:5432/KmeulenTrap4P23\n"
     ]
    }
   ],
   "source": [
    "# this is sqlalchemy script to login to the Banana database\n",
    "logging.getLogger('sqlalchemy.engine').setLevel(query_loglevel)\n",
    "db = tkp.db.Database(engine=engine, host=host, port=port,\n",
    "                     user=user, password=password, database=database)\n",
    "db.connect()\n",
    "session = db.Session()\n",
    "\n",
    "# Here i get the peak flux and the error on the peak flux from all the sources in the database\n",
    "fpeak = session.query(Extractedsource.f_peak).all()\n",
    "fpeake = session.query(Extractedsource.f_peak_err).all()\n",
    "califreq = np.load(\"freqlist.npy\")\n",
    "califlux = np.load(\"fluxlist.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query to find the variability parameters of the sources in a specific dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here I specifiy which dataset of the database to use\n",
    "dataset_id = 4\n",
    "\n",
    "VarParams = session.query(Varmetric,Runningcatalog).select_from(join(Varmetric,Runningcatalog)).filter(Runningcatalog.dataset_id == dataset_id).all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 2d array of all the sources except for the transients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotdata = [[VarParams[i].Runningcatalog.id, VarParams[i].Runningcatalog.wm_ra,\\\n",
    "             VarParams[i].Runningcatalog.wm_decl,VarParams[i].Runningcatalog.avg_ra_err,\\\n",
    "             VarParams[i].Runningcatalog.avg_decl_err, VarParams[i].Runningcatalog.datapoints,\\\n",
    "             session.query(Newsource).filter(Newsource.id==VarParams[i].Varmetric.newsource).one().newsource_type,\\\n",
    "             VarParams[i].Varmetric.newsource,VarParams[i].Varmetric.lightcurve_max, session.query(Newsource).filter(Newsource.id==VarParams[i].Varmetric.newsource).one().trigger_xtrsrc.id]\\\n",
    "            for i in range(len(VarParams)) if VarParams[i].Varmetric.newsource != None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The de Ruiter distance as shown in the Trap Paper section 4.4 https://arxiv.org/abs/1503.01526 \n",
    "\n",
    "def CalcDeRuiter(transient,ra2,ra2e,dec2,dec2e):\n",
    "    ra1 = transient['ra']\n",
    "    dec1 = transient['dec']\n",
    "    ra1e = transient['rae']\n",
    "    dec1e = transient['dece']\n",
    "\n",
    "    r=(np.sqrt((((-1*ra2 +ra1)**2)*(np.cos((dec1+dec2)/2))**2)/\\\n",
    "                       (ra1e**2+ra2e**2)+((-1*dec2+dec1)**2/(dec1e**2+dec2e**2))))\n",
    "    return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the fluxes heavily inspired on the de Ruiter distance as used by Bart's thesis: https://api-alumni.nl/media/uploads/theses/phd/lha-scheers-phd.pdf page 55\n",
    "\n",
    "def CompareFluxes(transient,pflux2,pflux2e,scale=1):\n",
    "    pflux1 = transient['pflux']*scale\n",
    "    pflux1e = transient['pfluxe']*scale\n",
    "    \n",
    "    r = np.sqrt((((-1*pflux2 +pflux1)**2))/\\\n",
    "                       (pflux1e**2+pflux2e**2))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the frequency flux scale based on supplied califreq and califlux data\n",
    "\n",
    "def CalcFreqScale(transient,datafreq,califreq,califlux):\n",
    "    \"\"\"Function for calculating the frequency scale\"\"\"\n",
    "    transfreq = transient.freq\n",
    "    for i in range(len(califreq)):\n",
    "        if transfreq - 0.005 <= califreq[i] <= transfreq + 0.005:\n",
    "            oldflux = califlux[i]\n",
    "        if datafreq - 0.005 <= califreq[i] <= datafreq + 0.005:\n",
    "            newflux = califlux[i]\n",
    "    scale = newflux/oldflux\n",
    "    return scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for pruning our candidate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectorForCandidates(rcheck,ycheck,checklight,deruiter=True):\n",
    "    \"\"\"Function for pruning the candidate list using both distance and lightcurve measurements\"\"\"\n",
    "    \n",
    "    print 'before:'\n",
    "    print len(Transients.instances)\n",
    "    oldlen = len(Transients.instances) + 1\n",
    "    \n",
    "# #   Repeat until no improvement in the length of the candidate list\n",
    "    while len(Transients.instances) - oldlen < 0:\n",
    "\n",
    "        translist = []\n",
    "#         rlist = []\n",
    "        oldlen = len(Transients.instances)\n",
    "        \n",
    "#         These lists are necessary to compare the candidate transients against each other\n",
    "        ralist = []\n",
    "        raelist = []\n",
    "        declist = []\n",
    "        decelist = []\n",
    "        pfluxlist = []\n",
    "        pfluxelist = []\n",
    "\n",
    "    # \"\"\"Check candidate transients against each other\"\"\"\n",
    "    \n",
    "    \n",
    "        for i in Transients.instances:\n",
    "            if not deruiter:\n",
    "                translist.append(i.radec)\n",
    "            else:\n",
    "                ralist.append(i.ra)\n",
    "                raelist.append(i.rae)\n",
    "                declist.append(i.dec)\n",
    "                decelist.append(i.dece)\n",
    "                pfluxlist.append(i.pflux)\n",
    "                pfluxelist.append(i.pfluxe)\n",
    "\n",
    "                \n",
    "        \n",
    "#       if we are not using deruiter distance use euclidean (it is slightly outdated and not used alot\n",
    "#       I would recommend just using the deruiterdistance method which also features the updated fluxcheckmethod)\n",
    "        if not deruiter:\n",
    "            index1list = []\n",
    "            index2list = []\n",
    "            translist = np.reshape(translist,(len(Transients.instances),2))\n",
    "            Z = distance.cdist(translist,translist,'euclidean')\n",
    "\n",
    "        # select on distance measure of 0.06 difference\n",
    "            for g in range(len(Z)):\n",
    "                for j in range(len(Z[g])):\n",
    "                    if Z[g][j] <=0.06 and Z[g][j] !=0.0:\n",
    "                        index1list.append(g)\n",
    "                        index2list.append(j)\n",
    "                    i = 0\n",
    "                    \n",
    "# the deletion process for notderuiterdistance                    \n",
    "            while i < len(index1list):\n",
    "\n",
    "                if checklight:\n",
    "\n",
    "\n",
    "                    try:\n",
    "                        if  Transients.instances[index2list[i]].pflux*0.8 <= Transients.instances[index1list[i]].pflux <= Transients.instances[index2list[i]].pflux*1.2:\n",
    "                            index1list.remove(index2list[i])\n",
    "                            Transients.instances[index1list[i]] = []\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                else:\n",
    "                    index1list.remove(index2list[i])\n",
    "                    Transients.instances[index1list[i]] = []\n",
    "\n",
    "\n",
    "                i+=1\n",
    "\n",
    "            i = 0\n",
    "            while i < len(Transients.instances):\n",
    "                if Transients.instances[i]:\n",
    "                    pass\n",
    "                else:\n",
    "                    del Transients.instances[i]\n",
    "                    i-=1     \n",
    "                i+=1\n",
    "                        \n",
    "                        \n",
    "#       \"here we are using deRuiter to calculate the fluxes\n",
    "\n",
    "        else:\n",
    "            h = 0\n",
    "            while h <(len(Transients.instances)):\n",
    "#               calculate both the deruiterdistance's and compare the fluxes.\n",
    "                r = CalcDeRuiter(vars(Transients.instances[h]),np.array(ralist),\\\n",
    "                                 np.array(raelist),np.array(declist),np.array(decelist))\n",
    "                if checklight:\n",
    "                    y = CompareFluxes(vars(Transients.instances[h]),np.array(pfluxlist),np.array(pfluxelist))\n",
    "                jk = 0\n",
    "                for j in range(len(r)):\n",
    "                    if jk >= len(Transients.instances):\n",
    "                        break\n",
    "                    if checklight:\n",
    "                        if r[j] <=rcheck and r[j]!= 0.0 and 0 < y[j] <=ycheck:\n",
    "                            del Transients.instances[h]\n",
    "                            h-=1\n",
    "                            jk=0\n",
    "                            break\n",
    "                    else:\n",
    "                        if r[j] <=rcheck and r[j]!= 0.0:\n",
    "                            del Transients.instances[h]\n",
    "                            h-=1\n",
    "                            jk=0\n",
    "                            break\n",
    "                    jk+=1\n",
    "                   \n",
    "                h+=1\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    # \"\"\"Check Candidates against all sources\"\"\"\n",
    "#     a zero candidate that is being tracked if the flux is comparable to the transient \n",
    "#     could be real things when it is consistently brighter or fainter than the candidate 1.\n",
    "#  Talk to Mark about pyc to get flux at specific coordinate ore look at the options. in the pyc-h \n",
    "\n",
    "        masterindex = []\n",
    "        ilist = []\n",
    "        for i in Transients.instances:\n",
    "            indexlist = []\n",
    "            \n",
    "#             again the outdated euclidean method\n",
    "            if not deruiter:\n",
    "                Y = distance.cdist(i.radec,X,'euclidean')\n",
    "\n",
    "                for g in Y:\n",
    "                    for j in range(len(g)):\n",
    "                        if checklight:\n",
    "                            if g[j] <=0.06 and 0.8*lightcata[j]<=i.pflux <= 1.2*lightcata[j]:\n",
    "                                indexlist.append(j)\n",
    "                        else:\n",
    "                            if g[j] <=0.06:\n",
    "                                indexlist.append(j)\n",
    "                \n",
    "#             the de Ruiter method \n",
    "            else:\n",
    "                r = CalcDeRuiter(vars(i),np.array(racata),np.array(raecata),np.array(deccata),np.array(dececata))\n",
    "                y = CompareFluxes(vars(i),np.array(lightcata),np.array(lightecata))\n",
    "                for j in range(len(r)):\n",
    "                    if checklight:\n",
    "                        if r[j] <=rcheck and y[j]<=ycheck:\n",
    "                            indexlist.append(j)\n",
    "                                \n",
    "                            \n",
    "                            \n",
    "                    else:\n",
    "                        if r[j] <=rcheck:\n",
    "                            indexlist.append(j)\n",
    "            masterindex.append(indexlist)\n",
    "            \n",
    "# removing the fake candidates\n",
    "        i = 0\n",
    "        j= 0\n",
    "        while i < len(masterindex):\n",
    "            if masterindex[i]:\n",
    "                del Transients.instances[j]\n",
    "                j-=1\n",
    "            i+=1\n",
    "            j+=1\n",
    "\n",
    "    print 'after:'    \n",
    "    print len(Transients.instances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for comparing transient candidate against external databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CheckOutsideDatabase(data,rcheck,ycheck,checklight,gamma,deruiter = True,euccutoff = 0.06):\n",
    "    \"\"\" Function for checking against outside database the data entry is for the database rcheck is condition \\\n",
    "where we check deruiter against, ycheck is where we check de flux against and checklight,gamma,deruiter\\\n",
    "are booleans which switch on checking the flux(checklight), checking using error on the flux(gamma) and \\\n",
    "using deruiter distance\n",
    "\n",
    "\"\"\"\n",
    "    scale =  CalcFreqScale(Transients.instances[0],data.freq,califreq,califlux)\n",
    "    masterindex = []\n",
    "    savedilist = []\n",
    "    print 'before:'\n",
    "\n",
    "    print len(Transients.instances)\n",
    "\n",
    "    for i in Transients.instances:\n",
    "        indexlist = []\n",
    "\n",
    "        if not deruiter:\n",
    "            Y = distance.cdist(i.radec,data.radec,'euclidean')\n",
    "            if gamma:\n",
    "                y = CompareFluxes(vars(i),np.array(data.pflux),np.array(data.pfluxe),scale)\n",
    "                \n",
    "                for g in Y:\n",
    "\n",
    "                    for j in range(len(g)):\n",
    "\n",
    "                        if g[j] <=euccutoff and y[j]>= ycheck:\n",
    "                            if i.id not in savedilist:\n",
    "                                FluxVar(vars(i),j,data,scale)\n",
    "                                savedilist.append(i.id)\n",
    "                            indexlist.append(j)\n",
    "\n",
    "                        elif g[j] <=euccutoff:\n",
    "                            indexlist.append(j)\n",
    "                    \n",
    "            else:\n",
    "                for g in Y:\n",
    "\n",
    "                    for j in range(len(g)):\n",
    "                        if checklight:\n",
    "\n",
    "                            if g[j] <=euccutoff and (i.pflux*scale <= 0.9*data.pflux[j] or i.pflux*scale>=1.1*data.pflux[j]):\n",
    "                                if i.id not in savedilist:\n",
    "                                    FluxVar(vars(i),j,data,scale)\n",
    "                                    savedilist.append(i.id)\n",
    "                                indexlist.append(j)\n",
    "\n",
    "                            elif g[j] <=euccutoff:\n",
    "                                indexlist.append(j)\n",
    "                        else:\n",
    "                            if g[j] <=euccutoff:\n",
    "                                indexlist.append(j)\n",
    "\n",
    "        else:\n",
    "\n",
    "            r = CalcDeRuiter(vars(i),np.array(data.ra),np.array(data.rae),np.array(data.dec),np.array(data.dece))\n",
    "            if gamma:\n",
    "                y = CompareFluxes(vars(i),np.array(data.pflux),np.array(data.pfluxe),scale)\n",
    "\n",
    "                for j in range(len(r)):\n",
    "\n",
    "                    if r[j] <=rcheck and y[j]>= ycheck:\n",
    "                        indexlist.append(j)\n",
    "                        if i.id not in savedilist:\n",
    "                            FluxVar(vars(i),j,data,scale)\n",
    "                            savedilist.append(i.id)\n",
    "\n",
    "                    elif r[j] <=rcheck:\n",
    "                        indexlist.append(j)\n",
    "\n",
    "            else:\n",
    "                for j in range(len(r)):\n",
    "                    if checklight:\n",
    "                        if r[j] <=rcheck and (i.pflux*scale <= 0.9*data.pflux[j] or i.pflux*scale>=1.1*data.pflux[j]):\n",
    "                            indexlist.append(j)\n",
    "                            if i.id not in savedilist:\n",
    "                                FluxVar(vars(i),j,data,scale)\n",
    "                                savedilist.append(i.id)\n",
    "                        elif r[j] <=rcheck:\n",
    "                            indexlist.append(j)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        if r[j] <=rcheck:\n",
    "                            indexlist.append(j)\n",
    "\n",
    "        masterindex.append(indexlist)\n",
    "    \n",
    "        \n",
    "    i = 0\n",
    "    while i < len(masterindex):\n",
    "        if not masterindex[i]:\n",
    "            PosVar(vars(Transients.instances[i]),data)\n",
    "        i+=1\n",
    "\n",
    "    print 'after:'  \n",
    "    print str(len(PosVar.instances)) +\" Interesting candidates\"\n",
    "    print str(len(FluxVar.instances)) + \" Flux Varying candidates\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class object for saving our candidate transients, class object for storing objects that have varying flux compared to external database and\n",
    "Initialize our transients class and other banana sources lists.\n",
    "\n",
    "(This piece of code has to be rerun everytime you adjust something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Transients(object):\n",
    "    instances = []\n",
    "    def __init__(self,ra,rae,dec,dece,ids,pflux,pfluxe):\n",
    "        self.id = ids\n",
    "        y = np.stack((ra,dec),axis = -1)\n",
    "        self.ra = ra\n",
    "        self.rae = rae\n",
    "        self.dec = dec\n",
    "        self.dece = dece\n",
    "        self.pflux = pflux\n",
    "        self.pfluxe = pfluxe\n",
    "        self.freq = 144\n",
    "        self.keys = ['yoloswag']\n",
    "        self.radec = np.reshape(y,(1,2))\n",
    "        Transients.instances.append(self)\n",
    "\n",
    "    def DelFalse(i):\n",
    "        del Transients.instances[i]\n",
    "\n",
    "class PosVar(object):\n",
    "    \"\"\"class object for storing objects that have a varying position compared to the database we are looking in\"\"\"\n",
    "    instances = []\n",
    "    def __init__(self,params,database):\n",
    "        self.id = params['id']            \n",
    "        self.ra = params['ra']\n",
    "        self.database = database\n",
    "        self.dataname = database.name\n",
    "        self.dec = params['dec']\n",
    "        self.radec = params['radec']\n",
    "        self.pflux = params['pflux']\n",
    "        try:\n",
    "            self.iflux = params['iflux']\n",
    "        except:\n",
    "            pass\n",
    "        PosVar.instances.append(self)\n",
    "    \n",
    "    \n",
    "class FluxVar(object):\n",
    "    \"\"\"class object for storing objects that have a varying flux compared to the database we are looking in\"\"\"\n",
    "    instances = []\n",
    "    def __init__(self,params,databaseentry,database,scale):\n",
    "        self.id = params['id']\n",
    "        self.ra = params['ra']\n",
    "        self.database = database\n",
    "        self.dataname = database.name\n",
    "        self.scale = scale\n",
    "        self.dec = params['dec']\n",
    "        self.radec = params['radec']\n",
    "        self.pflux = params['pflux']\n",
    "        self.entry = databaseentry\n",
    "        try:\n",
    "            self.iflux = params['iflux']\n",
    "        except:\n",
    "            pass\n",
    "        FluxVar.instances.append(self)\n",
    "    \n",
    "\n",
    "        \n",
    "racata = []\n",
    "raecata = []\n",
    "deccata = []\n",
    "dececata = []\n",
    "idcata = []\n",
    "lightcata = []\n",
    "lightecata = []\n",
    "for i in range(len(plotdata)):\n",
    "    if plotdata[i][6] == 1:\n",
    "        Transients(plotdata[i][1],plotdata[i][3],plotdata[i][2],plotdata[i][4],plotdata[i][0],fpeak[plotdata[i][-1]-1][0],fpeake[plotdata[i][-1]-1][0])\n",
    "    else:\n",
    "        racata.append(plotdata[i][1])\n",
    "        raecata.append(plotdata[i][3])\n",
    "        deccata.append(plotdata[i][2])\n",
    "        dececata.append(plotdata[i][4])\n",
    "        idcata.append(plotdata[i][0])\n",
    "        lightcata.append(fpeak[plotdata[i][-1]-1][0])\n",
    "        lightecata.append(fpeake[plotdata[i][-1]-1][0])\n",
    "X = np.stack((racata,deccata),axis = -1)\n",
    "\n",
    "racata = np.array(racata)\n",
    "raecata = np.array(raecata)\n",
    "dececata = np.array(dececata)\n",
    "deccta = np.array(deccata)\n",
    "idcata = np.array(idcata)\n",
    "lightcata = np.array(lightcata)\n",
    "lightecata = np.array(lightecata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we call the function for calculating the de ruiter distance between candidates and our found sources and if True is given we also check if the max of the lightcurve of the sources compared fall withing 5 sigma flux of each other (thus making it increasingly likely for   the source to be a sidelobe)\n",
    "\n",
    "This extra flux comparison is used in order to not potentially write of a faint or bright transient close to a known source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:\n",
      "34\n",
      "after:\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "SelectorForCandidates(rcheck = 3, ycheck = 5,checklight = True, deruiter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate links\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2940\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2050\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2625\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2606\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/3114\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/3025\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2630\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2562\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/3112\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2733\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2072\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/3072\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2116\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2527\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2933\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2320\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2313\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/1955\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2528\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/1905\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2422\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2143\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2516\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2854\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2294\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2004\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2358\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/3046\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/1899\n",
      "http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2677\n"
     ]
    }
   ],
   "source": [
    "print \"Candidate links\"\n",
    "for i in Transients.instances:\n",
    "    print websiteURL+str(i.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print out in latex format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2940 & 188.587 & 49.241 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2940} &  \\\\\n",
      "2050 & 183.241 & 48.807 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2050} &  \\\\\n",
      "2625 & -174.198 & 44.600 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2625} &  \\\\\n",
      "2606 & 185.716 & 50.449 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2606} &  \\\\\n",
      "3114 & 188.157 & 48.285 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/3114} &  \\\\\n",
      "3025 & 186.352 & 45.248 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/3025} &  \\\\\n",
      "2630 & 185.855 & 47.079 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2630} &  \\\\\n",
      "2562 & 185.532 & 46.755 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2562} &  \\\\\n",
      "3112 & 188.145 & 48.359 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/3112} &  \\\\\n",
      "2733 & 186.477 & 44.940 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2733} &  \\\\\n",
      "2072 & 183.364 & 48.387 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2072} &  \\\\\n",
      "3072 & 187.778 & 47.987 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/3072} &  \\\\\n",
      "2116 & 183.524 & 50.479 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2116} &  \\\\\n",
      "2527 & 185.349 & 50.590 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2527} &  \\\\\n",
      "2933 & 188.278 & 45.483 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2933} &  \\\\\n",
      "2320 & 182.490 & 46.301 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2320} &  \\\\\n",
      "2313 & 182.437 & 46.921 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2313} &  \\\\\n",
      "1955 & 181.759 & 48.032 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/1955} &  \\\\\n",
      "2528 & 185.368 & 50.815 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2528} &  \\\\\n",
      "1905 & 181.302 & 48.298 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/1905} &  \\\\\n",
      "2422 & 184.777 & 48.499 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2422} &  \\\\\n",
      "2143 & 183.791 & 46.454 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2143} &  \\\\\n",
      "2516 & 185.295 & 48.711 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2516} &  \\\\\n",
      "2854 & 187.216 & 48.967 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2854} &  \\\\\n",
      "2294 & 182.103 & 49.725 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2294} &  \\\\\n",
      "2004 & 182.021 & 49.810 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2004} &  \\\\\n",
      "2358 & 182.671 & 49.125 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2358} &  \\\\\n",
      "3046 & 186.532 & 47.615 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/3046} &  \\\\\n",
      "1899 & 181.150 & 48.949 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/1899} &  \\\\\n",
      "2677 & 186.056 & 46.336 & \\url{http://banana.transientskp.org/r4/vlo_KmeulenTrap4P23/runningcatalog/2677} &  \\\\\n"
     ]
    }
   ],
   "source": [
    "for i in Transients.instances:\n",
    "    print str(i.id) + \" \" + \"&\"+ \" \" + '%0.3f' %i.ra + \" \" + \"&\"+ \" \"+ \"%0.3f\" %(i.dec) +\\\n",
    "    \" \" + \"&\" + \" \" +latexURL +str(i.id)+\"}\" +\" \" + '&' + \"  \"+\"\\\\\" + \"\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tgss \n",
    "is the object which has tggs survey data for the field of P23 loaded into it.\n",
    "could probably just automate it here but lets leave it for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'radec', 'ra', 'rae', 'dec', 'dece', 'pflux', 'pfluxe', 'freq']\n",
      "147.5\n",
      "tgss\n"
     ]
    }
   ],
   "source": [
    "tgss = dl.ReadData(\"tgss\")\n",
    "print tgss.keys\n",
    "print tgss.freq\n",
    "print tgss.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:\n",
      "34\n",
      "after:\n",
      "29 Interesting candidates\n",
      "376 Flux Varying candidates\n"
     ]
    }
   ],
   "source": [
    "CheckOutsideDatabase(tgss,rcheck = 5,ycheck = 5,checklight = True, gamma = True,deruiter = True,euccutoff = .06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VLSSr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'ascii'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'ascii'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'ascii'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'ascii'\n",
      "['name', 'radec', 'ra', 'rae', 'dec', 'dece', 'pflux', 'pfluxe', 'freq']\n"
     ]
    }
   ],
   "source": [
    "# Probably need to pip install xlrd for excell support in pandas\n",
    "vlssr = dl.ReadData('vlssr')\n",
    "print vlssr.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:\n",
      "34\n",
      "after:\n",
      "161 Interesting candidates\n",
      "132 Flux Varying candidates\n"
     ]
    }
   ],
   "source": [
    "CheckOutsideDatabase(vlssr,rcheck = 5,ycheck = 5,checklight = True, gamma = True,deruiter = False,euccutoff = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the same position Fluxvariating sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in FluxVar.instances:\n",
    "    \n",
    "    print \"Data compared to \" + i.database.name\n",
    "    print websiteURL+str(i.id)\n",
    "    print 'bananaflux: ' + str(i.pflux*i.scale)\n",
    "    print i.database.name+'flux: ' + str(i.database.pflux[i.entry])\n",
    "    print \"------------------------\"\n",
    "        \n",
    "#     if i.database == 'vssr':\n",
    "        \n",
    "#         print 'bananaflux: ' + str(i.pflux * vlssrscale)\n",
    "#         print 'vlssrflux: ' + str(vssr.pflux[i.entry])\n",
    "#         print \"########################\"\n",
    "#     print vssr.ra[i.entry]\n",
    "#     print vssr.dec[i.entry]\n",
    "#     print i.ra\n",
    "#     print i.dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the Position variating sources in Latex ready format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print \"\\\\begin{longtable}{c|c|c|c|c|c} \\n\\\n",
    "\\\\toprule \\nDatabase & Id & Ra & Dec & Link & y/n  \\\\\\\\\\\\midrule \\n\\\\endfirsthead \\n\\\\toprule \\\n",
    "\\nDatabase & Id & Ra & Dec & Link & y/n  \\\\\\\\\\\\midrule \\n\\\\endhead \\n\\\\bottomrule \\n\\\\endfoot \\n\\\\bottomrule\"\n",
    "\n",
    "# define caption for table\n",
    "print \"\\\\caption{ Comparison position of candidates with different databases for the 10 min interval data} \\n\\\\endlastfoot\"\n",
    "lastname = None\n",
    "for i in PosVar.instances:\n",
    "    if i.database.name != lastname and lastname:\n",
    "        print \"\\\\hline\"\n",
    "    print i.database.name +\" \"+ \"&\"+ \" \"+ str(i.id) + \" \" + \"&\"+ \" \" + '%0.3f' %i.ra + \" \" + \"&\"+ \" \"+ \"%0.3f\" %(i.dec) +\\\n",
    "    \" \" + \"&\" + \" \" +latexURL +str(i.id)+\"}\" +\" \" + '&' + \"  \"+\"\\\\\" + \"\\\\\"\n",
    "    \n",
    "    lastname = i.database.name\n",
    "\n",
    "print \"\\\\end{longtable}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samesieslist = []\n",
    "for i in range(len(PosVar.instances)):\n",
    "    samesie = False\n",
    "    for j in range(len(samesieslist)):\n",
    "        if PosVar.instances[i].id == samesieslist[j][0]:\n",
    "            samesieslist[j][1] = samesieslist[j][1] + \" \\& \" + PosVar.instances[i].database.name\n",
    "            samesie = True\n",
    "    if not samesie:\n",
    "        samesieslist.append([PosVar.instances[i].id,PosVar.instances[i].database.name,PosVar.instances[i]])\n",
    "    \n",
    "samesieslist = sorted(samesieslist, key=itemgetter(1))\n",
    "\n",
    "print \"\\\\begin{longtable}{c|c|c|c|c|c} \\n\\\n",
    "\\\\toprule \\nDatabase & Id & Ra & Dec & Link & y/n  \\\\\\\\\\\\midrule \\n\\\\endfirsthead \\n\\\\toprule \\\n",
    "\\nDatabase & Id & Ra & Dec & Link & y/n  \\\\\\\\\\\\midrule \\n\\\\endhead \\n\\\\bottomrule \\n\\\\endfoot \\n\\\\bottomrule\"\n",
    "\n",
    "# define caption for table\n",
    "print \"\\\\caption{ Comparison position of candidates with different databases for the 10 min interval data} \\n\\\\endlastfoot\"\n",
    "lastname = None\n",
    "for i in samesieslist:\n",
    "    if i[1] != lastname and lastname:\n",
    "        print \"\\\\hline\"\n",
    "    print i[1] +\" \"+ \"&\"+ \" \"+ str(i[0]) + \" \" + \"&\"+ \" \" + '%0.3f' %i[2].ra + \" \" + \"&\"+ \" \"+ \"%0.3f\" %(i[2].dec) +\\\n",
    "    \" \" + \"&\" + \" \" +latexURL +str(i[0])+\"}\" +\" \" + '&' + \"  \"+\"\\\\\" + \"\\\\\"\n",
    "    \n",
    "    lastname = i[1]\n",
    "\n",
    "print \"\\\\end{longtable}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIECE OF CODE WHERE WE TRIED TO EQUAL EUCDISTANCE TO RUITERDISTANCE VIA NUMERICAL INTEGRATIONS DIDNT WORK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The de Ruiter distance as shown in the Trap Paper section 4.4 https://arxiv.org/abs/1503.01526\n",
    "\n",
    "# def CalcDeRuiterspec(ra1,ra1e,dec1,dec1e,ra2,ra2e,dec2,dec2e):\n",
    "#     r=(np.sqrt((((-1*ra2 +ra1)**2)*(np.cos((dec1+dec2)/2))**2)/\\\n",
    "#                        (ra1e**2+ra2e**2)+((-1*dec2+dec1)**2/(dec1e**2+dec2e**2))))\n",
    "#     return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def CompareEuc(data,racata,raecata,deccata,dececata,X):\n",
    "    \n",
    "#     ra = np.linspace(min(abs(racata)),max(abs(racata)),100)\n",
    "#     dec = np.linspace(min(abs(np.array(deccata))),max(abs(np.array(deccata))),100)\n",
    "#     rae = np.linspace(min(abs(raecata)),max(abs(raecata)),100)\n",
    "#     dece = np.linspace(min(abs(np.array(dececata))),max(abs(np.array(dececata))),100)\n",
    "    \n",
    "# #   Initialize radec inorder to have the first value be a real value instead of radec = []\n",
    "#     radeccomplete = None\n",
    "#     radececomplete = None\n",
    "    \n",
    "#     for i in range(len(ra)):\n",
    "#         for j in range(len(dec)):\n",
    "#             if not radeccomplete:\n",
    "#                 radeccomplete =[[ra[i],dec[j]]]\n",
    "#                 radececomplete = [[rae[i],dece[j]]]\n",
    "#             else:\n",
    "#                 radeccomplete.append([ra[i],dec[j]])\n",
    "#                 radececomplete.append([rae[i],dece[j]])\n",
    "\n",
    "#     radece = np.matrix(radececomplete)\n",
    "#     radec = np.matrix(radeccomplete)\n",
    "\n",
    "# #   calculate the euler distance\n",
    "#     Y = distance.cdist(radec,radec,'euclidean')\n",
    "\n",
    "    \n",
    "# #   Calculate all the deruiter distances\n",
    "#     r = []\n",
    "#     for i in range(len(radec)):\n",
    "        \n",
    "#         h = CalcDeRuiterspec(float(radec[i][:,0]),float(radece[i][:,0]),float(radec[i][:,1]),float(radece[i][:,0]),np.array(radec[:][:,0]),np.array(radece[:][:,0]),np.array(radec[:][:,1]),np.array(radece[:][:,1]))\n",
    "#         r.append(h)\n",
    "\n",
    "# #   Reshape the de ruiter distances in an Array compatible with the euclidean distance array\n",
    "#     r = np.array(r)\n",
    "#     r = np.reshape(r,(len(r),len(r)))\n",
    "    \n",
    "# #   combine the euclidean and the deruiter distances\n",
    "# #     z = np.column_stack((Y,r))\n",
    "#     return Y,r\n",
    "\n",
    "                            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y,r = CompareEuc(tgss,racata,raecata,deccata,dececata,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print r[368]\n",
    "# print Y[368]\n",
    "\n",
    "# print r[867]\n",
    "# print Y[867]\n",
    "# plt.scatter(r[368],Y[368])\n",
    "# plt.scatter(r[867],Y[867])\n",
    "# # print r[369][568]\n",
    "# # print Y[369][568]\n",
    "\n",
    "# # print r[867][4368]\n",
    "# # print Y[867][4368]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print r[0]\n",
    "# # print Y[0]\n",
    "\n",
    "# for i in range(len(r)):\n",
    "#     for j in range(len(r[i])):\n",
    "#         if Y[i][j] <=0.05 and Y[i][j]>0:\n",
    "#             print i\n",
    "#             print j\n",
    "#             print Y[i][j]\n",
    "#             print r[i][j]\n",
    "\n",
    "# # stop = False\n",
    "# # for i in range(len(Y)):\n",
    "# #     for j in range(len(Y[i])):\n",
    "# #         if r[i][j] -0.001 <= 5 <= r[i][j] +0.001:\n",
    "# #             print Y[i][j]\n",
    "# #             print r[i][j]\n",
    "# #             print \"______________\"\n",
    "# #     if stop:\n",
    "# #         break\n",
    "# # plt.scatter(Y,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Transients.instances)):\n",
    "    if Transients.instances[i].id == 3324:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = CompareFluxes(vars(Transients.instances[7]),np.array(lightcata),np.array(lightecata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(lightcata)):\n",
    "    if 0.594<=lightcata[j]<=0.7143 :\n",
    "        print j\n",
    "\n",
    "for i in range(len(r)):\n",
    "    if r[i] <=1:\n",
    "        print r[i]\n",
    "print 'yoloswag'\n",
    "print r[103]\n",
    "print r[225]\n",
    "print r[601]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print idcata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete double entries in transient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete candidates that have an euclidean distance measure of 0.04 or less with the rest of the sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
